{
 "cells": [
  {
   "source": [
    "# Notebook for fine-tuning a HuggingFace model for Named Entity Recognition through the HuggingFace Trainer-class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Heavily inspired by [this](https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb) notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will start off by importing necessary packages."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "source": [
    "We then define the model we want to use."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Maltehb/-l-ctra-danish-electra-small-cased\""
   ]
  },
  {
   "source": [
    "We will start off by loading the [DaNE](https://www.aclweb.org/anthology/2020.lrec-1.565/) dataset, through the HuggingFace `datasets` function [`load_dataset()`]((https://huggingface.co/docs/datasets/package_reference/loading_methods.html#datasets.load_dataset))."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "referenced_widgets": [
      "69caab03d6264fef9fc5649bffff5e20",
      "3f74532faa86412293d90d3952f38c4a",
      "50615aa59c7247c4804ca5cbc7945bd7",
      "fe962391292a413ca55dc932c4279fa7",
      "299f4b4c07654e53a25f8192bd1d7bbd",
      "ad04ed1038154081bbb0c1444784dcc2",
      "7c667ad22b5740d5a6319f1b1e3a8097",
      "46c2b043c0f84806978784a45a4e203b",
      "80e2943be35f46eeb24c8ab13faa6578",
      "de5956b5008d4fdba807bae57509c393",
      "931db1f7a42f4b46b7ff8c2e1262b994",
      "6c1db72efff5476e842c1386fadbbdba",
      "ccd2f37647c547abb4c719b75a26f2de",
      "d30a66df5c0145e79693e09789d96b81",
      "5fa26fc336274073abbd1d550542ee33",
      "2b34de08115d49d285def9269a53f484",
      "d426be871b424affb455aeb7db5e822e",
      "160bf88485f44f5cb6eaeecba5e0901f",
      "745c0d47d672477b9bb0dae77b926364",
      "d22ab78269cd4ccfbcf70c707057c31b",
      "d298eb19eeff453cba51c2804629d3f4",
      "a7204ade36314c86907c562e0a2158b8",
      "e35d42b2d352498ca3fc8530393786b2",
      "75103f83538d44abada79b51a1cec09e",
      "f6253931d90543e9b5fd0bb2d615f73a",
      "051aa783ff9e47e28d1f9584043815f5",
      "0984b2a14115454bbb009df71c1cf36f",
      "8ab9dfce29854049912178941ef1b289",
      "c9de740e007141958545e269372780a4",
      "cbea68b25d6d4ba09b2ce0f27b1726d5",
      "5781fc45cf8d486cb06ed68853b2c644",
      "d2a92143a08a4951b55bab9bc0a6d0d3",
      "a14c3e40e5254d61ba146f6ec88eae25",
      "c4ffe6f624ce4e978a0d9b864544941a",
      "1aca01c1d8c940dfadd3e7144bb35718",
      "9fbbaae50e6743f2aa19342152398186",
      "fea27ca6c9504fc896181bc1ff5730e5",
      "940d00556cb849b3a689d56e274041c2",
      "5cdf9ed939fb42d4bf77301c80b8afca",
      "94b39ccfef0b4b08bf2fb61bb0a657c1",
      "9a55087c85b74ea08b3e952ac1d73cbe",
      "2361ab124daf47cc885ff61f2899b2af",
      "1a65887eb37747ddb75dc4a40f7285f2",
      "3c946e2260704e6c98593136bd32d921",
      "50d325cdb9844f62a9ecc98e768cb5af",
      "aa781f0cfe454e9da5b53b93e9baabd8",
      "6bb68d3887ef43809eb23feb467f9723",
      "7e29a8b952cf4f4ea42833c8bf55342f",
      "dd5997d01d8947e4b1c211433969b89b",
      "2ace4dc78e2f4f1492a181bcd63304e7",
      "bbee008c2791443d8610371d1f16b62b",
      "31b1c8a2e3334b72b45b083688c1a20c",
      "7fb7c36adc624f7dbbcb4a831c1e4f63",
      "0b7c8f1939074794b3d9221244b1344d",
      "a71908883b064e1fbdddb547a8c41743",
      "2f5223f26c8541fc87e91d2205c39995"
     ]
    },
    "id": "s_AY1ATSIrIq",
    "outputId": "fd0578d1-8895-443d-b56f-5908de9f1b6b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset dane (C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"dane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are both a train, validation and test split with the features: \"id, tokens, pos_tags, chunk_tags and ner_tags\"."
   ]
  },
  {
   "source": [
    "The first sentence from the training data can be seen below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "X6HrpprwIrIz",
    "outputId": "d7670bc0-42e4-4c09-8a6a-5c018ded7d95"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dep_ids': [2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  7,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  14,\n",
       "  15,\n",
       "  11,\n",
       "  17,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  18,\n",
       "  5],\n",
       " 'dep_labels': [35,\n",
       "  16,\n",
       "  28,\n",
       "  33,\n",
       "  19,\n",
       "  35,\n",
       "  16,\n",
       "  35,\n",
       "  18,\n",
       "  35,\n",
       "  18,\n",
       "  1,\n",
       "  1,\n",
       "  33,\n",
       "  22,\n",
       "  12,\n",
       "  32,\n",
       "  11,\n",
       "  35,\n",
       "  10,\n",
       "  30,\n",
       "  16,\n",
       "  34],\n",
       " 'lemmas': ['på',\n",
       "  'fredag',\n",
       "  'have',\n",
       "  'SiD',\n",
       "  'invitere',\n",
       "  'til',\n",
       "  'reception',\n",
       "  'i',\n",
       "  'SID-hus',\n",
       "  'i',\n",
       "  'anledning',\n",
       "  'af',\n",
       "  'at',\n",
       "  'formand',\n",
       "  'Kjeld',\n",
       "  'Christensen',\n",
       "  'gå',\n",
       "  'ind',\n",
       "  'i',\n",
       "  'den',\n",
       "  'glad',\n",
       "  'tresser',\n",
       "  '.'],\n",
       " 'morph_tags': ['AdpType=Prep',\n",
       "  'Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  '_',\n",
       "  'Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part',\n",
       "  'AdpType=Prep',\n",
       "  'Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'AdpType=Prep',\n",
       "  'Definite=Def|Gender=Neut|Number=Sing',\n",
       "  'AdpType=Prep',\n",
       "  'Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'AdpType=Prep',\n",
       "  '_',\n",
       "  'Definite=Def|Gender=Com|Number=Sing',\n",
       "  '_',\n",
       "  '_',\n",
       "  'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  '_',\n",
       "  'AdpType=Prep',\n",
       "  'Number=Plur|PronType=Dem',\n",
       "  'Degree=Pos|Number=Plur',\n",
       "  'Definite=Ind|Gender=Com|Number=Plur',\n",
       "  '_'],\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'pos_tags': [11,\n",
       "  12,\n",
       "  5,\n",
       "  7,\n",
       "  3,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  16,\n",
       "  12,\n",
       "  7,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  11,\n",
       "  14,\n",
       "  6,\n",
       "  12,\n",
       "  10],\n",
       " 'sent_id': 'train-v2-0\\n',\n",
       " 'text': 'På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere.\\n',\n",
       " 'tok_ids': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23],\n",
       " 'tokens': ['På',\n",
       "  'fredag',\n",
       "  'har',\n",
       "  'SID',\n",
       "  'inviteret',\n",
       "  'til',\n",
       "  'reception',\n",
       "  'i',\n",
       "  'SID-huset',\n",
       "  'i',\n",
       "  'anledning',\n",
       "  'af',\n",
       "  'at',\n",
       "  'formanden',\n",
       "  'Kjeld',\n",
       "  'Christensen',\n",
       "  'går',\n",
       "  'ind',\n",
       "  'i',\n",
       "  'de',\n",
       "  'glade',\n",
       "  'tressere',\n",
       "  '.']}"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is evident that the tags are already turned into ids where the \"actual\" labels, in turn, can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)"
      ]
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "datasets[\"train\"].features[f\"ner_tags\"]"
   ]
  },
  {
   "source": [
    "__The following section is a direct copy-paste from the original notebook.__"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the labels are lists of `ClassLabel`, the actual names of the labels are nested in the `feature` attribute of the object above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "label_list = datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SZy5tRB_IrI7",
    "outputId": "ba8f2124-e485-488f-8c0c-254f34f24f13",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dep_ids</th>\n      <th>dep_labels</th>\n      <th>lemmas</th>\n      <th>morph_tags</th>\n      <th>ner_tags</th>\n      <th>pos_tags</th>\n      <th>sent_id</th>\n      <th>text</th>\n      <th>tok_ids</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[7, 7, 7, 7, 6, 7, 17, 7, 14, 13, 12, 13, 7, 13, 13, 7, 0, 17, 17]</td>\n      <td>[punct, nsubj, cop, det, amod, amod, dep, punct, compound:prt, nsubj, det, obj, aux, mark, punct, punct, root, nsubj, punct]</td>\n      <td>[\", det, være, en, ren, administrativ, opgave, ,, som, amts-politiker, ingen, indflydelse, have, på, ,, \", sige, Kaalund, .]</td>\n      <td>[_, Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Degree=Pos|Gender=Com|Number=Sing, Definite=Ind|Degree=Pos|Gender=Com|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, PartType=Inf, Definite=Def|Gender=Com|Number=Plur, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, AdpType=Prep, _, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER, O]</td>\n      <td>[PUNCT, PRON, AUX, DET, ADJ, ADJ, NOUN, PUNCT, ADP, NOUN, DET, NOUN, AUX, ADP, PUNCT, PUNCT, VERB, PROPN, PUNCT]</td>\n      <td>train-v2-546\\n</td>\n      <td>\"Det er en ren administrativ opgave, som amts-politikerne ingen indflydelse har på,\" siger Kaalund.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]</td>\n      <td>[\", Det, er, en, ren, administrativ, opgave, ,, som, amts-politikerne, ingen, indflydelse, har, på, ,, \", siger, Kaalund, .]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[5, 5, 4, 2, 0, 5]</td>\n      <td>[case, amod, cc, conj, root, punct]</td>\n      <td>[i, ensfarvet, eller, nistret, udgave, .]</td>\n      <td>[AdpType=Prep, Definite=Ind|Degree=Pos|Number=Sing, _, Definite=Ind|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _]</td>\n      <td>[O, O, O, O, O, O]</td>\n      <td>[ADP, ADJ, CCONJ, ADJ, NOUN, PUNCT]</td>\n      <td>train-v2-1381\\n</td>\n      <td>I ensfarvet eller nistret udgave.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6]</td>\n      <td>[I, ensfarvet, eller, nistret, udgave, .]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[4, 3, 4, 5, 0, 5, 5, 5, 8, 13, 13, 13, 8, 13, 13, 13, 20, 20, 20, 5, 20, 20, 24, 20, 5]</td>\n      <td>[case, advmod, amod, obl, root, nsubj, obj, xcomp, obj, case, det, amod, obl, dep, amod, dep, punct, cc, nsubj, conj, advmod, obj, advmod, amod, punct]</td>\n      <td>[på, lidt, lang, sigt, se, de, Europa, rejse, sig, som, en, politisk, rival, og, økonomisk, konkurrent, ,, og, det, bekomme, ikke, al, lige, vel, .]</td>\n      <td>[AdpType=Prep, Degree=Pos, Degree=Cmp, Definite=Ind|Gender=Com|Number=Sing, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Case=Nom|Number=Plur|Person=3|PronType=Prs, _, VerbForm=Inf|Voice=Act, Case=Acc|Person=3|PronType=Prs|Reflex=Yes, PartType=Inf, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, Definite=Ind|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, _, Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, Degree=Pos|Number=Plur, _, _, _]</td>\n      <td>[O, O, O, O, O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[ADP, ADV, ADJ, NOUN, VERB, PRON, PROPN, VERB, PRON, ADP, DET, ADJ, NOUN, CCONJ, ADJ, NOUN, PUNCT, CCONJ, PRON, VERB, ADV, ADJ, ADV, ADV, PUNCT]</td>\n      <td>train-v2-3097\\n</td>\n      <td>På lidt længere sigt ser de Europa rejse sig som en politisk rival og økonomisk konkurrent, og det bekommer ikke alle lige vel.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]</td>\n      <td>[På, lidt, længere, sigt, ser, de, Europa, rejse, sig, som, en, politisk, rival, og, økonomisk, konkurrent, ,, og, det, bekommer, ikke, alle, lige, vel, .]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[2, 0, 2, 2, 6, 2, 9, 9, 2, 11, 9, 2]</td>\n      <td>[advmod, root, nsubj, advmod, case, obl, cc, aux, conj, det, obj, punct]</td>\n      <td>[nu, komme, jeg, daglig, på, toilet, og, have, tabe, en, kilo, .]</td>\n      <td>[_, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Case=Nom|Gender=Com|Number=Sing|Person=1|PronType=Prs, Degree=Pos, AdpType=Prep, Definite=Def|Gender=Neut|Number=Sing, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Gender=Neut|Number=Sing|PronType=Ind, Definite=Ind|Gender=Neut|Number=Sing, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[ADV, VERB, PRON, ADV, ADP, NOUN, CCONJ, AUX, VERB, DET, NOUN, PUNCT]</td>\n      <td>train-v2-2640\\n</td>\n      <td>Nu kommer jeg daglig på toilettet og har tabt et kilo.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n      <td>[Nu, kommer, jeg, daglig, på, toilettet, og, har, tabt, et, kilo, .]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[4, 3, 4, 0, 6, 4, 4, 9, 4, 4]</td>\n      <td>[punct, amod, nsubj, root, advmod, advmod, obj, case, obl, punct]</td>\n      <td>[-, tyrkisk, mand, drikke, næsten, altid, raki, til, mad, .]</td>\n      <td>[_, Degree=Pos|Number=Plur, Definite=Ind|Gender=Com|Number=Plur, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, _, Foreign=Yes, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, _]</td>\n      <td>[O, B-MISC, O, O, O, O, O, O, O, O]</td>\n      <td>[PUNCT, ADJ, NOUN, VERB, ADV, ADV, X, ADP, NOUN, PUNCT]</td>\n      <td>train-v2-2825\\n</td>\n      <td>- Tyrkiske mænd drikker næsten altid raki til maden.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</td>\n      <td>[-, Tyrkiske, mænd, drikker, næsten, altid, raki, til, maden, .]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[3, 3, 18, 3, 7, 7, 3, 9, 7, 7, 18, 14, 14, 18, 16, 14, 18, 0, 18, 22, 22, 18, 22, 26, 26, 22, 28, 22, 18, 34, 32, 34, 34, 18, 37, 37, 34, 37, 38, 34, 49, 49, 45, 45, 49, 49, 49, 49, 34, 49, 54, 54, 54, 50, 49, 61, 58, 61, 61, 61, 49, 65, 65, 65, 61, 65, 69, 69, 65, 71, 69, 71, 76, 76, 76, 72, 34, 79, 76, 79, 18]</td>\n      <td>[det, nummod, nsubj, punct, nsubj, cop, acl:relcl, case, nmod, punct, aux, case, det, obl, case, nmod, advmod, root, punct, mark, expl, obj, mark, case, det, obl, case, nummod, punct, punct, nmod:poss, nsubj, cop, amod, mark, mark, acl:relcl, obj, nmod:poss, punct, mark, nsubj, case, amod, nmod, cop, det, amod, obl, advmod, case, det, amod, obl, punct, nsubj, case, obl, aux, aux, acl:relcl, case, det, amod, obl, punct, nsubj, cop, acl:relcl, case, obl, advmod, case, det, amod, obl, punct, punct, nmod, punct, punct]</td>\n      <td>[den, ni, EF-land, ,, der, være, medlem, af, WEU, ,, have, i, en, erklæring, til, unionstraktat, nærmere, uddybe, ,, hvad, der, tænke, på, i, denne, revision, i, 1996, :, \", WEU, medlemsstat, være, enig, om, at, styrke, WEU, rolle, ,, idet, perspektiv, på, lang, sigt, være, en, fælles, forsvarspolitik, inden, for, den, europæisk, union, ,, som, med, tid, ville, kunne, føre, til, en, fælles, forsvar, ,, der, være, forenelig, med, forsvar, inden, for, den, atlantisk, alliance, \", (, NATO, ), .]</td>\n      <td>[Number=Plur|PronType=Dem, NumType=Card, Definite=Ind|Gender=Neut|Number=Plur, _, PartType=Inf, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Ind|Gender=Neut|Number=Plur, AdpType=Prep, _, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, AdpType=Prep, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, Degree=Cmp, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, _, Number=Sing|PronType=Int,Rel, PartType=Inf, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Pass, AdpType=Prep, AdpType=Prep, Gender=Com|Number=Sing|PronType=Dem, Definite=Ind|Gender=Com|Number=Sing, AdpType=Prep, NumType=Card, _, _, Case=Gen, Definite=Ind|Gender=Com|Number=Plur, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Degree=Pos|Number=Plur, AdpType=Prep, PartType=Inf, VerbForm=Inf|Voice=Act, Case=Gen, Definite=Ind|Gender=Com|Number=Sing, _, _, Definite=Def|Gender=Neut|Number=Sing, AdpType=Prep, Degree=Cmp, Definite=Ind|Gender=Com|Number=Sing, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Gender=Com|Number=Sing|PronType=Ind, Degree=Pos, Definite=Ind|Gender=Com|Number=Sing, _, AdpType=Prep, Gender=Com|Number=Sing|PronType=Dem, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, PartType=Inf, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, VerbForm=Inf|Voice=Act, VerbForm=Inf|Voice=Act, AdpType=Prep, Gender=Neut|Number=Sing|PronType=Ind, Degree=Pos, Definite=Ind|Gender=Neut|Number=Sing, _, PartType=Inf, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing, AdpType=Prep, Definite=Def|Gender=Neut|Number=Sing, _, AdpType=Prep, Gender=Com|Number=Sing|PronType=Dem, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, _, _, _, _]</td>\n      <td>[O, O, B-MISC, O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O, B-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-ORG, I-ORG, I-ORG, O, O, B-ORG, O, O]</td>\n      <td>[DET, NUM, NOUN, PUNCT, ADV, AUX, NOUN, ADP, PROPN, PUNCT, AUX, ADP, DET, NOUN, ADP, NOUN, ADV, VERB, PUNCT, PRON, ADV, VERB, ADP, ADP, DET, NOUN, ADP, NUM, PUNCT, PUNCT, PROPN, NOUN, AUX, ADJ, ADP, PART, VERB, PROPN, NOUN, PUNCT, SCONJ, NOUN, ADP, ADJ, NOUN, AUX, DET, ADJ, NOUN, ADV, ADP, DET, ADJ, NOUN, PUNCT, PRON, ADP, NOUN, AUX, AUX, VERB, ADP, DET, ADJ, NOUN, PUNCT, ADV, AUX, ADJ, ADP, NOUN, ADV, ADP, DET, ADJ, NOUN, PUNCT, PUNCT, PROPN, PUNCT, PUNCT]</td>\n      <td>train-v2-2002\\n</td>\n      <td>De ni EF-lande, der er medlemmer af WEU, har i en erklæring til unionstraktaten nærmere uddybet, hvad der tænkes på i denne revision i 1996: \"WEUs medlemsstater er enige om at styrke WEUs rolle, idet perspektivet på længere sigt er en fælles forsvarspolitik inden for Den Europæiske Union, som med tiden vil kunne føre til et fælles forsvar, der er foreneligt med forsvaret inden for Den Atlantiske Alliance\" (NATO).\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81]</td>\n      <td>[De, ni, EF-lande, ,, der, er, medlemmer, af, WEU, ,, har, i, en, erklæring, til, unionstraktaten, nærmere, uddybet, ,, hvad, der, tænkes, på, i, denne, revision, i, 1996, :, \", WEUs, medlemsstater, er, enige, om, at, styrke, WEUs, rolle, ,, idet, perspektivet, på, længere, sigt, er, en, fælles, forsvarspolitik, inden, for, Den, Europæiske, Union, ,, som, med, tiden, vil, kunne, føre, til, et, fælles, forsvar, ,, der, er, foreneligt, med, forsvaret, inden, for, Den, Atlantiske, Alliance, \", (, NATO, ), .]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[2, 0, 4, 2, 2]</td>\n      <td>[advmod, root, cc, conj, punct]</td>\n      <td>[både, ude, og, inde, .]</td>\n      <td>[_, _, _, _, _]</td>\n      <td>[O, O, O, O, O]</td>\n      <td>[ADV, ADV, CCONJ, ADV, PUNCT]</td>\n      <td>train-v2-307\\n</td>\n      <td>Både ude og inde.\\n</td>\n      <td>[1, 2, 3, 4, 5]</td>\n      <td>[Både, ude, og, inde, .]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[13, 13, 13, 13, 13, 13, 8, 13, 13, 13, 13, 13, 0, 16, 16, 13, 16, 20, 20, 16, 13, 13, 24, 13, 24, 24, 24, 29, 24, 13]</td>\n      <td>[cc, nsubj, aux, aux, xcomp, iobj, case, obl, punct, mark, nsubj, aux, root, det, amod, obj, dep, det, amod, conj, punct, dep, advmod, dep, nsubj, advmod, obj, case, obl, punct]</td>\n      <td>[men, nogen, måtte, have, hviske, general, i, øre, ,, at, plan, ville, medføre, en, økologisk, katastrofe, og, en, global, ramaskrig, ,, for, pludselig, høre, man, ikke, meget, til, de, .]</td>\n      <td>[_, Gender=Com|Number=Sing|PronType=Ind, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, VerbForm=Inf|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Definite=Def|Gender=Com|Number=Sing, AdpType=Prep, Definite=Def|Gender=Neut|Number=Sing, _, _, Definite=Def|Gender=Com|Number=Plur, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, VerbForm=Inf|Voice=Act, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, Gender=Neut|Number=Sing|PronType=Ind, Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing, Definite=Ind|Gender=Neut|Number=Sing, _, _, _, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Case=Nom|Gender=Com|PronType=Ind, _, Definite=Ind|Degree=Cmp|Number=Sing, AdpType=Prep, Case=Acc|Number=Plur|Person=3|PronType=Prs, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[CCONJ, PRON, AUX, AUX, VERB, NOUN, ADP, NOUN, PUNCT, SCONJ, NOUN, AUX, VERB, DET, ADJ, NOUN, CCONJ, DET, ADJ, NOUN, PUNCT, CCONJ, ADV, VERB, PRON, ADV, ADJ, ADP, PRON, PUNCT]</td>\n      <td>train-v2-3669\\n</td>\n      <td>Men nogen må have hvisket generalen i øret, at planerne ville medføre en økologisk katastrofe og et globalt ramaskrig, for pludselig hørte man ikke mere til dem.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]</td>\n      <td>[Men, nogen, må, have, hvisket, generalen, i, øret, ,, at, planerne, ville, medføre, en, økologisk, katastrofe, og, et, globalt, ramaskrig, ,, for, pludselig, hørte, man, ikke, mere, til, dem, .]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[2, 0, 11, 3, 11, 11, 8, 11, 11, 11, 2, 14, 14, 11, 2]</td>\n      <td>[nsubj, root, mark, punct, mark, nsubj, obl, advmod, aux, aux, advcl, case, nummod, obl, punct]</td>\n      <td>[angreb, komme, efter, ,, at, by, nat, igennem, være, blive, ramme, af, 400, raket, .]</td>\n      <td>[Definite=Def|Gender=Neut|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, AdpType=Prep, _, _, Definite=Def|Gender=Com|Number=Sing, Definite=Def|Gender=Com|Number=Sing, _, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, AdpType=Prep, NumType=Card, Definite=Ind|Gender=Com|Number=Plur, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[NOUN, VERB, ADP, PUNCT, SCONJ, NOUN, NOUN, ADV, AUX, AUX, VERB, ADP, NUM, NOUN, PUNCT]</td>\n      <td>train-v2-59\\n</td>\n      <td>Angrebet kom efter, at byen natten igennem var blevet ramt af 400 raketter.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n      <td>[Angrebet, kom, efter, ,, at, byen, natten, igennem, var, blevet, ramt, af, 400, raketter, .]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[21, 1, 1, 5, 1, 11, 11, 10, 10, 7, 1, 13, 11, 13, 18, 17, 11, 17, 11, 21, 0, 23, 21, 21, 24, 29, 29, 29, 21, 33, 33, 33, 29, 33, 21]</td>\n      <td>[nsubj, flat, punct, amod, flat, nsubj, xcomp, case, amod, obl, acl:relcl, case, obl, flat, case, nummod, obl, compound:prt, punct, aux, root, amod, obj, advmod, obl:loc, case, det, amod, obl, case, det, nmod, nmod, flat, punct]</td>\n      <td>[Suzanne, Swannie, ,, dansk, tekstilkunstner, som, drive, af, ren, eventyrlyst, flytte, til, New, Foundland, for, 25, år, siden, ,, have, tage, flot, fotografi, med, hjem, på, den, årlig, sommerferie, hos, sin, mor, Bitten, Mørch, .]</td>\n      <td>[_, _, _, Definite=Ind|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, PartType=Inf, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, AdpType=Prep, Definite=Ind|Degree=Pos|Gender=Com|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, AdpType=Prep, _, _, AdpType=Prep, NumType=Card, Definite=Ind|Gender=Neut|Number=Plur, _, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Degree=Pos|Number=Plur, Definite=Ind|Gender=Neut|Number=Plur, _, _, AdpType=Prep, Gender=Com|Number=Sing|PronType=Dem, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, AdpType=Prep, Gender=Com|Number=Sing|Number[psor]=Sing|Person=3|Poss=Yes|PronType=Prs|Reflex=Yes, Definite=Ind|Gender=Com|Number=Sing, _, _, _]</td>\n      <td>[B-PER, I-PER, O, B-MISC, O, O, O, O, O, O, O, O, B-LOC, I-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER, O]</td>\n      <td>[PROPN, PROPN, PUNCT, ADJ, NOUN, ADP, VERB, ADP, ADJ, NOUN, VERB, ADP, PROPN, PROPN, ADP, NUM, NOUN, ADV, PUNCT, AUX, VERB, ADJ, NOUN, ADV, ADV, ADP, DET, ADJ, NOUN, ADP, DET, NOUN, PROPN, PROPN, PUNCT]</td>\n      <td>train-v2-428\\n</td>\n      <td>Suzanne Swannie, dansk tekstilkunstner som drevet af ren eventyrlyst flyttede til New Foundland for 25 år siden, har taget flotte fotografier med hjem på den årlige sommerferie hos sin mor Bitten Mørch.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35]</td>\n      <td>[Suzanne, Swannie, ,, dansk, tekstilkunstner, som, drevet, af, ren, eventyrlyst, flyttede, til, New, Foundland, for, 25, år, siden, ,, har, taget, flotte, fotografier, med, hjem, på, den, årlige, sommerferie, hos, sin, mor, Bitten, Mørch, .]</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case=False, strip_accents = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "a5hBlsrHIrJL",
    "outputId": "acdaa98a-a8cd-4a20-89b8-cc26437bbe90"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2914, 2390, 1931, 1944, 19054, 5, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "tokenizer(\"Hej dette er en sætning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
    "\n",
    "If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument `is_split_into_words=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2914, 16, 2390, 1931, 1944, 19054, 17270, 77, 2505, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "tokenizer([\"Hej\", \",\", \"dette\", \"er\", \"en\", \"sætning\", \"opdelt\", \"i\", \"ord\", \".\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let's look at an example of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Hun', 'er', 'selv', 'på', 'femte', 'år', 'lykkeligt', 'gift', 'med', 'sin', 'socialdemokratiske', 'partifælle', ',', 'Mogens', 'Lykketoft', '.']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][4]\n",
    "print(example[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[CLS]', 'Hun', 'er', 'selv', 'på', 'femte', 'år', 'lykkeligt', 'gift', 'med', 'sin', 'socialdemokratiske', 'parti', '##f', '##ælle', ',', 'Mogens', 'Lykke', '##to', '##ft', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n",
    "\n",
    "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a `[CLS]` and a `[SEP]` above) and then because of those possible splits of words in multiple tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "len(example[f\"ner_tags\"]), len(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, the tokenizer returns outputs that have a `word_ids` method which can help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 14, 14, 15, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to `None` and all other tokens to their respective word. This way, we can align the labels with the processed input ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22 22\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"ner_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We're now ready to write the function that will preprocess our samples. We feed them to the `tokenizer` with the argument `truncation=True` (to truncate texts that are bigger than the maximum size allowed by the model) and `is_split_into_words=True` (as seen above). Then we align the labels with the token ids using the strategy we picked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "-b70jh26IrJS",
    "outputId": "acd3a42d-985b-44ee-9daa-af5d944ce1d9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 2892, 7344, 1968, 21277, 1035, 15218, 1939, 13297, 1992, 77, 21277, 1035, 17, 6086, 77, 5752, 1937, 1934, 11245, 29800, 10214, 2423, 1999, 77, 1966, 7298, 3071, 6832, 1010, 18, 3], [2, 3767, 3481, 1926, 2204, 13765, 1926, 10668, 77, 2265, 2029, 3094, 4528, 16, 1981, 1944, 3908, 22864, 1940, 18, 3], [2, 3541, 7118, 1926, 4264, 77, 5986, 3832, 30090, 1926, 24415, 1956, 18, 3], [2, 8695, 1940, 10240, 7001, 4490, 2809, 15509, 2201, 1962, 1956, 2852, 17, 16556, 1010, 5911, 1027, 1968, 2161, 3071, 17, 1926, 8075, 8216, 1931, 1987, 3676, 1927, 2552, 2546, 13703, 16, 1934, 1963, 1968, 3137, 23388, 1926, 6424, 16016, 2123, 18, 3], [2, 2555, 1931, 2161, 1955, 15556, 2143, 28528, 4988, 1956, 2429, 22703, 8562, 1049, 3701, 16, 17997, 13706, 7265, 2048, 18, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 1, 2, 2, 2, 0, -100]]}"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "source": [
    "tokenize_and_align_labels(datasets['train'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading cached processed dataset at C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6\\cache-9d9cc0e513a632a3.arrow\n",
      "Loading cached processed dataset at C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6\\cache-bf2d64edcf1ef7fa.arrow\n",
      "Loading cached processed dataset at C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6\\cache-1341493b0c81719d.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the `AutoModelForTokenClassification` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "TlqNaB8jIrJW",
    "outputId": "84916cf3-6e6c-47f3-d081-032ec30a4132",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at Maltehb/-l-ctra-danish-electra-small-cased were not used when initializing ElectraForTokenClassification: ['generator.embeddings.word_embeddings.weight', 'generator.embeddings.position_embeddings.weight', 'generator.embeddings.token_type_embeddings.weight', 'generator.embeddings.LayerNorm.weight', 'generator.embeddings.LayerNorm.bias', 'generator.encoder.layer.0.attention.self.query.weight', 'generator.encoder.layer.0.attention.self.query.bias', 'generator.encoder.layer.0.attention.self.key.weight', 'generator.encoder.layer.0.attention.self.key.bias', 'generator.encoder.layer.0.attention.self.value.weight', 'generator.encoder.layer.0.attention.self.value.bias', 'generator.encoder.layer.0.attention.output.dense.weight', 'generator.encoder.layer.0.attention.output.dense.bias', 'generator.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.encoder.layer.0.intermediate.dense.weight', 'generator.encoder.layer.0.intermediate.dense.bias', 'generator.encoder.layer.0.output.dense.weight', 'generator.encoder.layer.0.output.dense.bias', 'generator.encoder.layer.0.output.LayerNorm.weight', 'generator.encoder.layer.0.output.LayerNorm.bias', 'generator.encoder.layer.1.attention.self.query.weight', 'generator.encoder.layer.1.attention.self.query.bias', 'generator.encoder.layer.1.attention.self.key.weight', 'generator.encoder.layer.1.attention.self.key.bias', 'generator.encoder.layer.1.attention.self.value.weight', 'generator.encoder.layer.1.attention.self.value.bias', 'generator.encoder.layer.1.attention.output.dense.weight', 'generator.encoder.layer.1.attention.output.dense.bias', 'generator.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.encoder.layer.1.intermediate.dense.weight', 'generator.encoder.layer.1.intermediate.dense.bias', 'generator.encoder.layer.1.output.dense.weight', 'generator.encoder.layer.1.output.dense.bias', 'generator.encoder.layer.1.output.LayerNorm.weight', 'generator.encoder.layer.1.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.query.weight', 'generator.encoder.layer.2.attention.self.query.bias', 'generator.encoder.layer.2.attention.self.key.weight', 'generator.encoder.layer.2.attention.self.key.bias', 'generator.encoder.layer.2.attention.self.value.weight', 'generator.encoder.layer.2.attention.self.value.bias', 'generator.encoder.layer.2.attention.output.dense.weight', 'generator.encoder.layer.2.attention.output.dense.bias', 'generator.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.intermediate.dense.weight', 'generator.encoder.layer.2.intermediate.dense.bias', 'generator.encoder.layer.2.output.dense.weight', 'generator.encoder.layer.2.output.dense.bias', 'generator.encoder.layer.2.output.LayerNorm.weight', 'generator.encoder.layer.2.output.LayerNorm.bias', 'generator.encoder.layer.3.attention.self.query.weight', 'generator.encoder.layer.3.attention.self.query.bias', 'generator.encoder.layer.3.attention.self.key.weight', 'generator.encoder.layer.3.attention.self.key.bias', 'generator.encoder.layer.3.attention.self.value.weight', 'generator.encoder.layer.3.attention.self.value.bias', 'generator.encoder.layer.3.attention.output.dense.weight', 'generator.encoder.layer.3.attention.output.dense.bias', 'generator.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.encoder.layer.3.intermediate.dense.weight', 'generator.encoder.layer.3.intermediate.dense.bias', 'generator.encoder.layer.3.output.dense.weight', 'generator.encoder.layer.3.output.dense.bias', 'generator.encoder.layer.3.output.LayerNorm.weight', 'generator.encoder.layer.3.output.LayerNorm.bias', 'generator.encoder.layer.4.attention.self.query.weight', 'generator.encoder.layer.4.attention.self.query.bias', 'generator.encoder.layer.4.attention.self.key.weight', 'generator.encoder.layer.4.attention.self.key.bias', 'generator.encoder.layer.4.attention.self.value.weight', 'generator.encoder.layer.4.attention.self.value.bias', 'generator.encoder.layer.4.attention.output.dense.weight', 'generator.encoder.layer.4.attention.output.dense.bias', 'generator.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.encoder.layer.4.intermediate.dense.weight', 'generator.encoder.layer.4.intermediate.dense.bias', 'generator.encoder.layer.4.output.dense.weight', 'generator.encoder.layer.4.output.dense.bias', 'generator.encoder.layer.4.output.LayerNorm.weight', 'generator.encoder.layer.4.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.self.query.weight', 'generator.encoder.layer.5.attention.self.query.bias', 'generator.encoder.layer.5.attention.self.key.weight', 'generator.encoder.layer.5.attention.self.key.bias', 'generator.encoder.layer.5.attention.self.value.weight', 'generator.encoder.layer.5.attention.self.value.bias', 'generator.encoder.layer.5.attention.output.dense.weight', 'generator.encoder.layer.5.attention.output.dense.bias', 'generator.encoder.layer.5.attention.output.LayerNorm.weight', 'generator.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.intermediate.dense.weight', 'generator.encoder.layer.5.intermediate.dense.bias', 'generator.encoder.layer.5.output.dense.weight', 'generator.encoder.layer.5.output.dense.bias', 'generator.encoder.layer.5.output.LayerNorm.weight', 'generator.encoder.layer.5.output.LayerNorm.bias', 'generator.encoder.layer.6.attention.self.query.weight', 'generator.encoder.layer.6.attention.self.query.bias', 'generator.encoder.layer.6.attention.self.key.weight', 'generator.encoder.layer.6.attention.self.key.bias', 'generator.encoder.layer.6.attention.self.value.weight', 'generator.encoder.layer.6.attention.self.value.bias', 'generator.encoder.layer.6.attention.output.dense.weight', 'generator.encoder.layer.6.attention.output.dense.bias', 'generator.encoder.layer.6.attention.output.LayerNorm.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.bias', 'generator.encoder.layer.6.intermediate.dense.weight', 'generator.encoder.layer.6.intermediate.dense.bias', 'generator.encoder.layer.6.output.dense.weight', 'generator.encoder.layer.6.output.dense.bias', 'generator.encoder.layer.6.output.LayerNorm.weight', 'generator.encoder.layer.6.output.LayerNorm.bias', 'generator.encoder.layer.7.attention.self.query.weight', 'generator.encoder.layer.7.attention.self.query.bias', 'generator.encoder.layer.7.attention.self.key.weight', 'generator.encoder.layer.7.attention.self.key.bias', 'generator.encoder.layer.7.attention.self.value.weight', 'generator.encoder.layer.7.attention.self.value.bias', 'generator.encoder.layer.7.attention.output.dense.weight', 'generator.encoder.layer.7.attention.output.dense.bias', 'generator.encoder.layer.7.attention.output.LayerNorm.weight', 'generator.encoder.layer.7.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.intermediate.dense.weight', 'generator.encoder.layer.7.intermediate.dense.bias', 'generator.encoder.layer.7.output.dense.weight', 'generator.encoder.layer.7.output.dense.bias', 'generator.encoder.layer.7.output.LayerNorm.weight', 'generator.encoder.layer.7.output.LayerNorm.bias', 'generator.encoder.layer.8.attention.self.query.weight', 'generator.encoder.layer.8.attention.self.query.bias', 'generator.encoder.layer.8.attention.self.key.weight', 'generator.encoder.layer.8.attention.self.key.bias', 'generator.encoder.layer.8.attention.self.value.weight', 'generator.encoder.layer.8.attention.self.value.bias', 'generator.encoder.layer.8.attention.output.dense.weight', 'generator.encoder.layer.8.attention.output.dense.bias', 'generator.encoder.layer.8.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.attention.output.LayerNorm.bias', 'generator.encoder.layer.8.intermediate.dense.weight', 'generator.encoder.layer.8.intermediate.dense.bias', 'generator.encoder.layer.8.output.dense.weight', 'generator.encoder.layer.8.output.dense.bias', 'generator.encoder.layer.8.output.LayerNorm.weight', 'generator.encoder.layer.8.output.LayerNorm.bias', 'generator.encoder.layer.9.attention.self.query.weight', 'generator.encoder.layer.9.attention.self.query.bias', 'generator.encoder.layer.9.attention.self.key.weight', 'generator.encoder.layer.9.attention.self.key.bias', 'generator.encoder.layer.9.attention.self.value.weight', 'generator.encoder.layer.9.attention.self.value.bias', 'generator.encoder.layer.9.attention.output.dense.weight', 'generator.encoder.layer.9.attention.output.dense.bias', 'generator.encoder.layer.9.attention.output.LayerNorm.weight', 'generator.encoder.layer.9.attention.output.LayerNorm.bias', 'generator.encoder.layer.9.intermediate.dense.weight', 'generator.encoder.layer.9.intermediate.dense.bias', 'generator.encoder.layer.9.output.dense.weight', 'generator.encoder.layer.9.output.dense.bias', 'generator.encoder.layer.9.output.LayerNorm.weight', 'generator.encoder.layer.9.output.LayerNorm.bias', 'generator.encoder.layer.10.attention.self.query.weight', 'generator.encoder.layer.10.attention.self.query.bias', 'generator.encoder.layer.10.attention.self.key.weight', 'generator.encoder.layer.10.attention.self.key.bias', 'generator.encoder.layer.10.attention.self.value.weight', 'generator.encoder.layer.10.attention.self.value.bias', 'generator.encoder.layer.10.attention.output.dense.weight', 'generator.encoder.layer.10.attention.output.dense.bias', 'generator.encoder.layer.10.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.output.LayerNorm.bias', 'generator.encoder.layer.10.intermediate.dense.weight', 'generator.encoder.layer.10.intermediate.dense.bias', 'generator.encoder.layer.10.output.dense.weight', 'generator.encoder.layer.10.output.dense.bias', 'generator.encoder.layer.10.output.LayerNorm.weight', 'generator.encoder.layer.10.output.LayerNorm.bias', 'generator.encoder.layer.11.attention.self.query.weight', 'generator.encoder.layer.11.attention.self.query.bias', 'generator.encoder.layer.11.attention.self.key.weight', 'generator.encoder.layer.11.attention.self.key.bias', 'generator.encoder.layer.11.attention.self.value.weight', 'generator.encoder.layer.11.attention.self.value.bias', 'generator.encoder.layer.11.attention.output.dense.weight', 'generator.encoder.layer.11.attention.output.dense.bias', 'generator.encoder.layer.11.attention.output.LayerNorm.weight', 'generator.encoder.layer.11.attention.output.LayerNorm.bias', 'generator.encoder.layer.11.intermediate.dense.weight', 'generator.encoder.layer.11.intermediate.dense.bias', 'generator.encoder.layer.11.output.dense.weight', 'generator.encoder.layer.11.output.dense.bias', 'generator.encoder.layer.11.output.LayerNorm.weight', 'generator.encoder.layer.11.output.LayerNorm.bias', 'generator.embeddings_project.weight', 'generator.embeddings_project.bias', 'generator_predictions.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.decoder.weight', 'generator_predictions.decoder.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.LayerNorm.weight', 'discriminator_predictions.LayerNorm.bias', 'discriminator_predictions.classifier.weight', 'discriminator_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at Maltehb/-l-ctra-danish-electra-small-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"test-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to define for our `Trainer` is how to compute the metrics from the predictions. Here we will load the [`seqeval`](https://github.com/chakki-works/seqeval) metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric takes list of labels for the predictions and references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "metadata": {},
     "execution_count": 26
    }
   ],
   "source": [
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "So we will need to do a bit of post-processing on our predictions:\n",
    "- select the predicted index (with the maximum logit) for each token\n",
    "- convert it to its string label\n",
    "- ignore everywhere we set a label of -100\n",
    "\n",
    "The following function does all this post-processing on the result of `Trainer.evaluate` (which is a namedtuple containing predictions and labels) before applying the metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy.\n",
    "\n",
    "Then we just need to pass all of this along with our datasets to the `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 14/4384 [00:04<22:37,  3.22it/s]"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-3435b262f1ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[0;32m   1051\u001b[0m                         \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1052\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1053\u001b[1;33m                     \u001b[0mtr_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1054\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_flos\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloating_point_ops\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[1;34m(self, model, inputs)\u001b[0m\n\u001b[0;32m   1459\u001b[0m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1460\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1461\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1462\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1463\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 245\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKASz-2vIrJi"
   },
   "source": [
    "The `evaluate` method allows you to evaluate again on the evaluation dataset or on another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "UOUcBkX8IrJi",
    "outputId": "de5b9dd6-9dc0-4702-cb43-55e9829fde25"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 71/71 [00:05<00:00, 12.63it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_loss': 0.10562150180339813,\n",
       " 'eval_precision': 0.7519305019305019,\n",
       " 'eval_recall': 0.8217299578059072,\n",
       " 'eval_f1': 0.785282258064516,\n",
       " 'eval_accuracy': 0.9738248703034114,\n",
       " 'eval_runtime': 5.7059,\n",
       " 'eval_samples_per_second': 98.845,\n",
       " 'epoch': 8.0,\n",
       " 'eval_mem_cpu_alloc_delta': 2736346,\n",
       " 'eval_mem_cpu_peaked_delta': 1854981}"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 71/71 [00:04<00:00, 15.48it/s]"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.7259615384615384,\n",
       "  'recall': 0.8206521739130435,\n",
       "  'f1': 0.7704081632653061,\n",
       "  'number': 184},\n",
       " 'MISC': {'precision': 0.6472491909385113,\n",
       "  'recall': 0.6872852233676976,\n",
       "  'f1': 0.6666666666666666,\n",
       "  'number': 291},\n",
       " 'ORG': {'precision': 0.6591549295774648,\n",
       "  'recall': 0.6610169491525424,\n",
       "  'f1': 0.6600846262341326,\n",
       "  'number': 354},\n",
       " 'PER': {'precision': 0.8732394366197183,\n",
       "  'recall': 0.8294314381270903,\n",
       "  'f1': 0.850771869639794,\n",
       "  'number': 299},\n",
       " 'overall_precision': 0.7205882352941176,\n",
       " 'overall_recall': 0.7384751773049646,\n",
       " 'overall_f1': 0.7294220665499124,\n",
       " 'overall_accuracy': 0.9634699497813057}"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'input_ids': [2,\n",
       "  4717,\n",
       "  5978,\n",
       "  13627,\n",
       "  3644,\n",
       "  9366,\n",
       "  3622,\n",
       "  3426,\n",
       "  1979,\n",
       "  17172,\n",
       "  2961,\n",
       "  17023,\n",
       "  1926,\n",
       "  21392,\n",
       "  1916,\n",
       "  23255,\n",
       "  1028,\n",
       "  27938,\n",
       "  2570,\n",
       "  1959,\n",
       "  16,\n",
       "  1934,\n",
       "  8901,\n",
       "  1996,\n",
       "  24049,\n",
       "  2335,\n",
       "  1944,\n",
       "  6,\n",
       "  6221,\n",
       "  1014,\n",
       "  6107,\n",
       "  6,\n",
       "  18,\n",
       "  3],\n",
       " 'labels': [-100,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to [update your model](https://huggingface.co/transformers/model_sharing.html) on the [🤗 Model Hub](https://huggingface.co/models). You can then use it only to generate results like the one shown in the first picture of this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-692cc0acfdc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hej mit navn er Malte\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1733\u001b[1;33m         output = self.prediction_loop(\n\u001b[0m\u001b[0;32m   1734\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1735\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\data\\data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mlabel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"label\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"label\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         batch = self.tokenizer.pad(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "trainer.predict(\"Hej mit navn er Malte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\".ajjaja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path.cwd() / \"models\"\n",
    "trainer.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "n9qywopnIrJH",
    "545PP3o8IrJV",
    "7k8ge1L1IrJk"
   ],
   "name": "Token classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "051aa783ff9e47e28d1f9584043815f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0984b2a14115454bbb009df71c1cf36f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbea68b25d6d4ba09b2ce0f27b1726d5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9de740e007141958545e269372780a4",
      "value": 1
     }
    },
    "0b7c8f1939074794b3d9221244b1344d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "160bf88485f44f5cb6eaeecba5e0901f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a65887eb37747ddb75dc4a40f7285f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa781f0cfe454e9da5b53b93e9baabd8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50d325cdb9844f62a9ecc98e768cb5af",
      "value": 1
     }
    },
    "1aca01c1d8c940dfadd3e7144bb35718": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_940d00556cb849b3a689d56e274041c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fea27ca6c9504fc896181bc1ff5730e5",
      "value": 1
     }
    },
    "2361ab124daf47cc885ff61f2899b2af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "299f4b4c07654e53a25f8192bd1d7bbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2ace4dc78e2f4f1492a181bcd63304e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b34de08115d49d285def9269a53f484": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f5223f26c8541fc87e91d2205c39995": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31b1c8a2e3334b72b45b083688c1a20c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f5223f26c8541fc87e91d2205c39995",
      "placeholder": "​",
      "style": "IPY_MODEL_a71908883b064e1fbdddb547a8c41743",
      "value": " 4.39k/? [00:00&lt;00:00, 149kB/s]"
     }
    },
    "3c946e2260704e6c98593136bd32d921": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e29a8b952cf4f4ea42833c8bf55342f",
      "placeholder": "​",
      "style": "IPY_MODEL_6bb68d3887ef43809eb23feb467f9723",
      "value": " 1063/0 [00:00&lt;00:00, 12337.52 examples/s]"
     }
    },
    "3f74532faa86412293d90d3952f38c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46c2b043c0f84806978784a45a4e203b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50615aa59c7247c4804ca5cbc7945bd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad04ed1038154081bbb0c1444784dcc2",
      "max": 7826,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_299f4b4c07654e53a25f8192bd1d7bbd",
      "value": 7826
     }
    },
    "50d325cdb9844f62a9ecc98e768cb5af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5781fc45cf8d486cb06ed68853b2c644": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cdf9ed939fb42d4bf77301c80b8afca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fa26fc336274073abbd1d550542ee33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69caab03d6264fef9fc5649bffff5e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50615aa59c7247c4804ca5cbc7945bd7",
       "IPY_MODEL_fe962391292a413ca55dc932c4279fa7"
      ],
      "layout": "IPY_MODEL_3f74532faa86412293d90d3952f38c4a"
     }
    },
    "6bb68d3887ef43809eb23feb467f9723": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c1db72efff5476e842c1386fadbbdba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b34de08115d49d285def9269a53f484",
      "placeholder": "​",
      "style": "IPY_MODEL_5fa26fc336274073abbd1d550542ee33",
      "value": " 28.7k/? [00:00&lt;00:00, 571kB/s]"
     }
    },
    "745c0d47d672477b9bb0dae77b926364": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7204ade36314c86907c562e0a2158b8",
      "max": 376971,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d298eb19eeff453cba51c2804629d3f4",
      "value": 376971
     }
    },
    "75103f83538d44abada79b51a1cec09e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c667ad22b5740d5a6319f1b1e3a8097": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e29a8b952cf4f4ea42833c8bf55342f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fb7c36adc624f7dbbcb4a831c1e4f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "80e2943be35f46eeb24c8ab13faa6578": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_931db1f7a42f4b46b7ff8c2e1262b994",
       "IPY_MODEL_6c1db72efff5476e842c1386fadbbdba"
      ],
      "layout": "IPY_MODEL_de5956b5008d4fdba807bae57509c393"
     }
    },
    "8ab9dfce29854049912178941ef1b289": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2a92143a08a4951b55bab9bc0a6d0d3",
      "placeholder": "​",
      "style": "IPY_MODEL_5781fc45cf8d486cb06ed68853b2c644",
      "value": " 8551/0 [00:00&lt;00:00, 25108.88 examples/s]"
     }
    },
    "931db1f7a42f4b46b7ff8c2e1262b994": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d30a66df5c0145e79693e09789d96b81",
      "max": 4473,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ccd2f37647c547abb4c719b75a26f2de",
      "value": 4473
     }
    },
    "940d00556cb849b3a689d56e274041c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94b39ccfef0b4b08bf2fb61bb0a657c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a55087c85b74ea08b3e952ac1d73cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a65887eb37747ddb75dc4a40f7285f2",
       "IPY_MODEL_3c946e2260704e6c98593136bd32d921"
      ],
      "layout": "IPY_MODEL_2361ab124daf47cc885ff61f2899b2af"
     }
    },
    "9fbbaae50e6743f2aa19342152398186": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94b39ccfef0b4b08bf2fb61bb0a657c1",
      "placeholder": "​",
      "style": "IPY_MODEL_5cdf9ed939fb42d4bf77301c80b8afca",
      "value": " 1043/0 [00:00&lt;00:00, 13590.50 examples/s]"
     }
    },
    "a14c3e40e5254d61ba146f6ec88eae25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1aca01c1d8c940dfadd3e7144bb35718",
       "IPY_MODEL_9fbbaae50e6743f2aa19342152398186"
      ],
      "layout": "IPY_MODEL_c4ffe6f624ce4e978a0d9b864544941a"
     }
    },
    "a71908883b064e1fbdddb547a8c41743": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7204ade36314c86907c562e0a2158b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa781f0cfe454e9da5b53b93e9baabd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad04ed1038154081bbb0c1444784dcc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbee008c2791443d8610371d1f16b62b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b7c8f1939074794b3d9221244b1344d",
      "max": 1586,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7fb7c36adc624f7dbbcb4a831c1e4f63",
      "value": 1586
     }
    },
    "c4ffe6f624ce4e978a0d9b864544941a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9de740e007141958545e269372780a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cbea68b25d6d4ba09b2ce0f27b1726d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd2f37647c547abb4c719b75a26f2de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d22ab78269cd4ccfbcf70c707057c31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75103f83538d44abada79b51a1cec09e",
      "placeholder": "​",
      "style": "IPY_MODEL_e35d42b2d352498ca3fc8530393786b2",
      "value": " 377k/377k [00:00&lt;00:00, 703kB/s]"
     }
    },
    "d298eb19eeff453cba51c2804629d3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d2a92143a08a4951b55bab9bc0a6d0d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d30a66df5c0145e79693e09789d96b81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d426be871b424affb455aeb7db5e822e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_745c0d47d672477b9bb0dae77b926364",
       "IPY_MODEL_d22ab78269cd4ccfbcf70c707057c31b"
      ],
      "layout": "IPY_MODEL_160bf88485f44f5cb6eaeecba5e0901f"
     }
    },
    "dd5997d01d8947e4b1c211433969b89b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbee008c2791443d8610371d1f16b62b",
       "IPY_MODEL_31b1c8a2e3334b72b45b083688c1a20c"
      ],
      "layout": "IPY_MODEL_2ace4dc78e2f4f1492a181bcd63304e7"
     }
    },
    "de5956b5008d4fdba807bae57509c393": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e35d42b2d352498ca3fc8530393786b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6253931d90543e9b5fd0bb2d615f73a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0984b2a14115454bbb009df71c1cf36f",
       "IPY_MODEL_8ab9dfce29854049912178941ef1b289"
      ],
      "layout": "IPY_MODEL_051aa783ff9e47e28d1f9584043815f5"
     }
    },
    "fe962391292a413ca55dc932c4279fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46c2b043c0f84806978784a45a4e203b",
      "placeholder": "​",
      "style": "IPY_MODEL_7c667ad22b5740d5a6319f1b1e3a8097",
      "value": " 28.7k/? [00:00&lt;00:00, 652kB/s]"
     }
    },
    "fea27ca6c9504fc896181bc1ff5730e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}