{
 "cells": [
  {
   "source": [
    "# Notebook for fine-tuning a HuggingFace model for Named Entity Recognition through the HuggingFace Trainer-class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Heavily inspired by [this](https://github.com/huggingface/notebooks/blob/master/examples/token_classification.ipynb) notebook."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "We will start off by importing necessary packages."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "IreSlFmlIrIm"
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset, load_metric"
   ]
  },
  {
   "source": [
    "We then define the model we want to use."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = \"Maltehb/-l-ctra-danish-electra-small-cased\""
   ]
  },
  {
   "source": [
    "We will start off by loading the [DaNE](https://www.aclweb.org/anthology/2020.lrec-1.565/) dataset, through the HuggingFace `datasets` function [`load_dataset()`]((https://huggingface.co/docs/datasets/package_reference/loading_methods.html#datasets.load_dataset))."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 270,
     "referenced_widgets": [
      "69caab03d6264fef9fc5649bffff5e20",
      "3f74532faa86412293d90d3952f38c4a",
      "50615aa59c7247c4804ca5cbc7945bd7",
      "fe962391292a413ca55dc932c4279fa7",
      "299f4b4c07654e53a25f8192bd1d7bbd",
      "ad04ed1038154081bbb0c1444784dcc2",
      "7c667ad22b5740d5a6319f1b1e3a8097",
      "46c2b043c0f84806978784a45a4e203b",
      "80e2943be35f46eeb24c8ab13faa6578",
      "de5956b5008d4fdba807bae57509c393",
      "931db1f7a42f4b46b7ff8c2e1262b994",
      "6c1db72efff5476e842c1386fadbbdba",
      "ccd2f37647c547abb4c719b75a26f2de",
      "d30a66df5c0145e79693e09789d96b81",
      "5fa26fc336274073abbd1d550542ee33",
      "2b34de08115d49d285def9269a53f484",
      "d426be871b424affb455aeb7db5e822e",
      "160bf88485f44f5cb6eaeecba5e0901f",
      "745c0d47d672477b9bb0dae77b926364",
      "d22ab78269cd4ccfbcf70c707057c31b",
      "d298eb19eeff453cba51c2804629d3f4",
      "a7204ade36314c86907c562e0a2158b8",
      "e35d42b2d352498ca3fc8530393786b2",
      "75103f83538d44abada79b51a1cec09e",
      "f6253931d90543e9b5fd0bb2d615f73a",
      "051aa783ff9e47e28d1f9584043815f5",
      "0984b2a14115454bbb009df71c1cf36f",
      "8ab9dfce29854049912178941ef1b289",
      "c9de740e007141958545e269372780a4",
      "cbea68b25d6d4ba09b2ce0f27b1726d5",
      "5781fc45cf8d486cb06ed68853b2c644",
      "d2a92143a08a4951b55bab9bc0a6d0d3",
      "a14c3e40e5254d61ba146f6ec88eae25",
      "c4ffe6f624ce4e978a0d9b864544941a",
      "1aca01c1d8c940dfadd3e7144bb35718",
      "9fbbaae50e6743f2aa19342152398186",
      "fea27ca6c9504fc896181bc1ff5730e5",
      "940d00556cb849b3a689d56e274041c2",
      "5cdf9ed939fb42d4bf77301c80b8afca",
      "94b39ccfef0b4b08bf2fb61bb0a657c1",
      "9a55087c85b74ea08b3e952ac1d73cbe",
      "2361ab124daf47cc885ff61f2899b2af",
      "1a65887eb37747ddb75dc4a40f7285f2",
      "3c946e2260704e6c98593136bd32d921",
      "50d325cdb9844f62a9ecc98e768cb5af",
      "aa781f0cfe454e9da5b53b93e9baabd8",
      "6bb68d3887ef43809eb23feb467f9723",
      "7e29a8b952cf4f4ea42833c8bf55342f",
      "dd5997d01d8947e4b1c211433969b89b",
      "2ace4dc78e2f4f1492a181bcd63304e7",
      "bbee008c2791443d8610371d1f16b62b",
      "31b1c8a2e3334b72b45b083688c1a20c",
      "7fb7c36adc624f7dbbcb4a831c1e4f63",
      "0b7c8f1939074794b3d9221244b1344d",
      "a71908883b064e1fbdddb547a8c41743",
      "2f5223f26c8541fc87e91d2205c39995"
     ]
    },
    "id": "s_AY1ATSIrIq",
    "outputId": "fd0578d1-8895-443d-b56f-5908de9f1b6b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset dane (C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6)\n"
     ]
    }
   ],
   "source": [
    "datasets = load_dataset(\"dane\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzfPtOMoIrIu"
   },
   "source": [
    "The `datasets` object itself is [`DatasetDict`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasetdict), which contains one key for the training, validation and test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are both a train, validation and test split with the features: \"id, tokens, pos_tags, chunk_tags and ner_tags\"."
   ]
  },
  {
   "source": [
    "The first sentence from the training data can be seen below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "X6HrpprwIrIz",
    "outputId": "d7670bc0-42e4-4c09-8a6a-5c018ded7d95"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'dep_ids': [2,\n",
       "  5,\n",
       "  5,\n",
       "  5,\n",
       "  0,\n",
       "  7,\n",
       "  5,\n",
       "  9,\n",
       "  7,\n",
       "  11,\n",
       "  7,\n",
       "  17,\n",
       "  17,\n",
       "  17,\n",
       "  14,\n",
       "  15,\n",
       "  11,\n",
       "  17,\n",
       "  22,\n",
       "  22,\n",
       "  22,\n",
       "  18,\n",
       "  5],\n",
       " 'dep_labels': [35,\n",
       "  16,\n",
       "  28,\n",
       "  33,\n",
       "  19,\n",
       "  35,\n",
       "  16,\n",
       "  35,\n",
       "  18,\n",
       "  35,\n",
       "  18,\n",
       "  1,\n",
       "  1,\n",
       "  33,\n",
       "  22,\n",
       "  12,\n",
       "  32,\n",
       "  11,\n",
       "  35,\n",
       "  10,\n",
       "  30,\n",
       "  16,\n",
       "  34],\n",
       " 'lemmas': ['på',\n",
       "  'fredag',\n",
       "  'have',\n",
       "  'SiD',\n",
       "  'invitere',\n",
       "  'til',\n",
       "  'reception',\n",
       "  'i',\n",
       "  'SID-hus',\n",
       "  'i',\n",
       "  'anledning',\n",
       "  'af',\n",
       "  'at',\n",
       "  'formand',\n",
       "  'Kjeld',\n",
       "  'Christensen',\n",
       "  'gå',\n",
       "  'ind',\n",
       "  'i',\n",
       "  'den',\n",
       "  'glad',\n",
       "  'tresser',\n",
       "  '.'],\n",
       " 'morph_tags': ['AdpType=Prep',\n",
       "  'Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  '_',\n",
       "  'Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part',\n",
       "  'AdpType=Prep',\n",
       "  'Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'AdpType=Prep',\n",
       "  'Definite=Def|Gender=Neut|Number=Sing',\n",
       "  'AdpType=Prep',\n",
       "  'Definite=Ind|Gender=Com|Number=Sing',\n",
       "  'AdpType=Prep',\n",
       "  '_',\n",
       "  'Definite=Def|Gender=Com|Number=Sing',\n",
       "  '_',\n",
       "  '_',\n",
       "  'Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act',\n",
       "  '_',\n",
       "  'AdpType=Prep',\n",
       "  'Number=Plur|PronType=Dem',\n",
       "  'Degree=Pos|Number=Plur',\n",
       "  'Definite=Ind|Gender=Com|Number=Plur',\n",
       "  '_'],\n",
       " 'ner_tags': [0,\n",
       "  0,\n",
       "  0,\n",
       "  3,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'pos_tags': [11,\n",
       "  12,\n",
       "  5,\n",
       "  7,\n",
       "  3,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  12,\n",
       "  11,\n",
       "  16,\n",
       "  12,\n",
       "  7,\n",
       "  7,\n",
       "  3,\n",
       "  9,\n",
       "  11,\n",
       "  14,\n",
       "  6,\n",
       "  12,\n",
       "  10],\n",
       " 'sent_id': 'train-v2-0\\n',\n",
       " 'text': 'På fredag har SID inviteret til reception i SID-huset i anledning af at formanden Kjeld Christensen går ind i de glade tressere.\\n',\n",
       " 'tok_ids': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23],\n",
       " 'tokens': ['På',\n",
       "  'fredag',\n",
       "  'har',\n",
       "  'SID',\n",
       "  'inviteret',\n",
       "  'til',\n",
       "  'reception',\n",
       "  'i',\n",
       "  'SID-huset',\n",
       "  'i',\n",
       "  'anledning',\n",
       "  'af',\n",
       "  'at',\n",
       "  'formanden',\n",
       "  'Kjeld',\n",
       "  'Christensen',\n",
       "  'går',\n",
       "  'ind',\n",
       "  'i',\n",
       "  'de',\n",
       "  'glade',\n",
       "  'tressere',\n",
       "  '.']}"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "datasets[\"train\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here it is evident that the tags are already turned into ids where the \"actual\" labels, in turn, can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], names_file=None, id=None), length=-1, id=None)"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "source": [
    "datasets[\"train\"].features[f\"ner_tags\"]"
   ]
  },
  {
   "source": [
    "__The following section is a direct copy-paste from the original notebook.__"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the labels are lists of `ClassLabel`, the actual names of the labels are nested in the `feature` attribute of the object above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC']"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "label_list = datasets[\"train\"].features[f\"ner_tags\"].feature.names\n",
    "label_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WHUmphG3IrI3"
   },
   "source": [
    "To get a sense of what the data looks like, the following function will show some examples picked randomly in the dataset (automatically decoding the labels in passing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "i3j8APAoIrI3"
   },
   "outputs": [],
   "source": [
    "from datasets import ClassLabel, Sequence\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def show_random_elements(dataset, num_examples=10):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "        elif isinstance(typ, Sequence) and isinstance(typ.feature, ClassLabel):\n",
    "            df[column] = df[column].transform(lambda x: [typ.feature.names[i] for i in x])\n",
    "    display(HTML(df.to_html()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "SZy5tRB_IrI7",
    "outputId": "ba8f2124-e485-488f-8c0c-254f34f24f13",
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>dep_ids</th>\n      <th>dep_labels</th>\n      <th>lemmas</th>\n      <th>morph_tags</th>\n      <th>ner_tags</th>\n      <th>pos_tags</th>\n      <th>sent_id</th>\n      <th>text</th>\n      <th>tok_ids</th>\n      <th>tokens</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>[6, 6, 2, 5, 6, 0, 6, 6, 10, 6, 6]</td>\n      <td>[cc, advmod, case, case, nummod, root, nsubj, obj, case, obl, punct]</td>\n      <td>[men, ikke, førend, i, 1969, gøre, han, nogen, ved, pladeindustri, .]</td>\n      <td>[_, _, AdpType=Prep, AdpType=Prep, NumType=Card, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Case=Nom|Gender=Com|Number=Sing|Person=3|PronType=Prs, Gender=Neut|Number=Sing|PronType=Ind, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[CCONJ, ADV, ADP, ADP, NUM, VERB, PRON, PRON, ADP, NOUN, PUNCT]</td>\n      <td>train-v2-912\\n</td>\n      <td>Men ikke førend i 1969 gjorde han noget ved pladeindustrien.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]</td>\n      <td>[Men, ikke, førend, i, 1969, gjorde, han, noget, ved, pladeindustrien, .]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>[3, 3, 4, 0, 4, 10, 10, 10, 8, 4, 14, 13, 10, 13, 4]</td>\n      <td>[det, amod, nsubj, root, punct, mark, nsubj, advmod, fixed, obj, nmod:poss, cc, obj, conj, punct]</td>\n      <td>[den, demokratisk, ideal, forudsætte, ,, at, vælger, en, bloc, dirigere, historie, og, udvikling, gang, .]</td>\n      <td>[Gender=Neut|Number=Sing|PronType=Dem, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Neut|Number=Sing, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, _, Definite=Def|Gender=Com|Number=Plur, Foreign=Yes, Foreign=Yes, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Case=Gen|Definite=Def|Gender=Com|Number=Sing, _, Case=Gen|Definite=Def|Gender=Com|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _]</td>\n      <td>[O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[DET, ADJ, NOUN, VERB, PUNCT, SCONJ, NOUN, X, X, VERB, NOUN, CCONJ, NOUN, NOUN, PUNCT]</td>\n      <td>train-v2-204\\n</td>\n      <td>Det demokratiske ideal forudsætter, at vælgerne en bloc dirigerer historiens og udviklingens gang.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n      <td>[Det, demokratiske, ideal, forudsætter, ,, at, vælgerne, en, bloc, dirigerer, historiens, og, udviklingens, gang, .]</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>[2, 0, 2, 7, 7, 7, 2, 2]</td>\n      <td>[nsubj, root, obj, case, advmod, nummod, obl, punct]</td>\n      <td>[han, opgøre, prisforskel, til, kun, tre, øre, .]</td>\n      <td>[Case=Nom|Gender=Com|Number=Sing|Person=3|PronType=Prs, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Def|Gender=Com|Number=Sing, AdpType=Prep, _, NumType=Card, Definite=Ind|Gender=Com|Number=Plur, _]</td>\n      <td>[O, O, O, O, O, O, O, O]</td>\n      <td>[PRON, VERB, NOUN, ADP, ADV, NUM, NOUN, PUNCT]</td>\n      <td>train-v2-2253\\n</td>\n      <td>Han opgør prisforskellen til kun tre øre.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n      <td>[Han, opgør, prisforskellen, til, kun, tre, øre, .]</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>[4, 1, 4, 0, 4, 7, 4, 4]</td>\n      <td>[nsubj, nummod, aux, root, advmod, case, nummod, punct]</td>\n      <td>[den, to, have, arbejde, sammen, siden, 1950, .]</td>\n      <td>[Number=Plur|PronType=Dem, NumType=Card, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, _, AdpType=Prep, NumType=Card, _]</td>\n      <td>[O, O, O, O, O, O, O, O]</td>\n      <td>[PRON, NUM, AUX, VERB, ADV, ADP, NUM, PUNCT]</td>\n      <td>train-v2-2006\\n</td>\n      <td>De to har arbejdet sammen siden 1950.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8]</td>\n      <td>[De, to, har, arbejdet, sammen, siden, 1950, .]</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>[0, 1, 4, 2, 1, 7, 1, 7, 7, 11, 9, 1]</td>\n      <td>[root, obj, case, nmod, obl:loc, cc, conj, obj, xcomp, advmod, advmod, punct]</td>\n      <td>[hælde, rest, af, piskefløde, i, og, lade, sauce, koge, lidt, ind, .]</td>\n      <td>[Mood=Imp, Definite=Def|Gender=Com|Number=Sing, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, _, _, Mood=Imp, Definite=Def|Gender=Com|Number=Sing, VerbForm=Inf|Voice=Act, Degree=Pos, _, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[VERB, NOUN, ADP, NOUN, ADV, CCONJ, VERB, NOUN, VERB, ADV, ADV, PUNCT]</td>\n      <td>train-v2-1828\\n</td>\n      <td>Hæld resten af piskefløden i og lad saucen koge lidt ind.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]</td>\n      <td>[Hæld, resten, af, piskefløden, i, og, lad, saucen, koge, lidt, ind, .]</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>[2, 0, 2, 2, 2, 12, 12, 12, 12, 12, 12, 2, 14, 12, 17, 17, 14, 22, 22, 19, 19, 12, 22, 22, 22, 27, 25, 22, 42, 42, 32, 42, 42, 42, 42, 42, 42, 42, 42, 42, 42, 22, 44, 42, 42, 47, 45, 49, 42, 2]</td>\n      <td>[nsubj, root, advmod, advmod, xcomp, punct, cc, nsubj, cop, advmod, det, conj, case, nmod, case, det, obl, punct, advmod, fixed, fixed, conj, nsubj, obj, xcomp, case, obl, punct, mark, advmod, det, nsubj, aux, xcomp, punct, mark, nsubj, advmod, aux, aux, obj, advcl, case, advmod, obl:loc, case, obl, case, obl, punct]</td>\n      <td>[det, være, ellers, ikke, tillade, ,, men, Einar, være, vist, en, særtilfælde, i, meget, end, en, forstand, ,, i, hver, fald, lade, konduktør, han, være, i, fred, ,, da, først, hans, kammerat, have, bedyre, ,, at, de, sagtens, kunne, have, Einar, ligge, på, tværs, ind, over, sig, under, tur, .]</td>\n      <td>[Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, _, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, _, _, _, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, _, Gender=Neut|Number=Sing|PronType=Ind, Definite=Ind|Gender=Neut|Number=Sing, AdpType=Prep, Definite=Ind|Degree=Cmp|Number=Sing, _, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, _, AdpType=Prep, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Neut|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Definite=Def|Gender=Com|Number=Sing, Case=Acc|Gender=Com|Number=Sing|Person=3|PronType=Prs, VerbForm=Inf|Voice=Act, AdpType=Prep, Definite=Ind|Gender=Com|Number=Sing, _, _, _, Number[psor]=Sing|Person=3|Poss=Yes|PronType=Prs, Definite=Ind|Gender=Com|Number=Plur, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, _, _, Case=Nom|Number=Plur|Person=3|PronType=Prs, _, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, VerbForm=Inf|Voice=Act, _, Tense=Pres|VerbForm=Part, AdpType=Prep, _, _, AdpType=Prep, Case=Acc|Person=3|PronType=Prs|Reflex=Yes, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, _]</td>\n      <td>[O, O, O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-PER, O, O, O, O, O, O, O, O, O]</td>\n      <td>[PRON, VERB, ADV, ADV, VERB, PUNCT, CCONJ, PROPN, AUX, ADV, DET, NOUN, ADP, ADJ, ADP, DET, NOUN, PUNCT, ADP, DET, NOUN, VERB, NOUN, PRON, VERB, ADP, NOUN, PUNCT, SCONJ, ADV, DET, NOUN, AUX, VERB, PUNCT, SCONJ, PRON, ADV, AUX, AUX, PROPN, VERB, ADP, ADV, ADV, ADP, PRON, ADP, NOUN, PUNCT]</td>\n      <td>train-v2-1143\\n</td>\n      <td>Det er ellers ikke tilladt, men Einar var vist et særtilfælde i mere end én forstand, i hvert fald lod konduktøren ham være i fred, da først hans kammerater havde bedyret, at de sagtens kunne have Einar liggende på tværs ind over sig under turen.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]</td>\n      <td>[Det, er, ellers, ikke, tilladt, ,, men, Einar, var, vist, et, særtilfælde, i, mere, end, én, forstand, ,, i, hvert, fald, lod, konduktøren, ham, være, i, fred, ,, da, først, hans, kammerater, havde, bedyret, ,, at, de, sagtens, kunne, have, Einar, liggende, på, tværs, ind, over, sig, under, turen, .]</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>[3, 3, 0, 6, 6, 3, 10, 10, 10, 3, 13, 13, 3, 15, 13, 17, 15, 19, 20, 13, 20, 19, 25, 25, 19, 30, 30, 30, 30, 25, 3]</td>\n      <td>[nsubj, aux, root, case, amod, obl, case, det, amod, obl, cc, aux, conj, amod, obj, cc, conj, advmod, case, obl, nmod, cc, case, det, nmod, case, det, nummod, amod, nmod, punct]</td>\n      <td>[Europa, ville, stå, overfor, kolossal, udfordring, i, den, komme, år, og, skulle, finde, ny, vej, og, rolle, både, til, sig, selv, og, i, sin, forhold, til, den, to, gammel, supermagt, .]</td>\n      <td>[_, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, VerbForm=Inf|Voice=Act, AdpType=Prep, Degree=Pos|Number=Plur, Definite=Ind|Gender=Com|Number=Plur, AdpType=Prep, Number=Plur|PronType=Dem, Tense=Pres|VerbForm=Part, Definite=Ind|Gender=Neut|Number=Plur, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, VerbForm=Inf|Voice=Act, Degree=Pos|Number=Plur, Definite=Ind|Gender=Com|Number=Plur, _, Definite=Ind|Gender=Com|Number=Plur, _, AdpType=Prep, Case=Acc|Person=3|PronType=Prs|Reflex=Yes, PronType=Dem, _, AdpType=Prep, Gender=Neut|Number=Sing|Number[psor]=Sing|Person=3|Poss=Yes|PronType=Prs|Reflex=Yes, Definite=Ind|Gender=Neut|Number=Sing, AdpType=Prep, Number=Plur|PronType=Dem, NumType=Card, Degree=Pos|Number=Plur, Definite=Ind|Gender=Com|Number=Plur, _]</td>\n      <td>[B-LOC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[PROPN, AUX, VERB, ADP, ADJ, NOUN, ADP, DET, VERB, NOUN, CCONJ, AUX, VERB, ADJ, NOUN, CCONJ, NOUN, ADV, ADP, PRON, PRON, CCONJ, ADP, DET, NOUN, ADP, DET, NUM, ADJ, NOUN, PUNCT]</td>\n      <td>train-v2-839\\n</td>\n      <td>Europa vil stå overfor kolossale udfordringer i de kommende år og skal finde nye veje og roller både til sig selv og i sit forhold til de to gamle supermagter.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]</td>\n      <td>[Europa, vil, stå, overfor, kolossale, udfordringer, i, de, kommende, år, og, skal, finde, nye, veje, og, roller, både, til, sig, selv, og, i, sit, forhold, til, de, to, gamle, supermagter, .]</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>[7, 4, 4, 7, 6, 4, 0, 9, 7, 9, 12, 7, 14, 12, 7]</td>\n      <td>[expl, case, nmod:poss, obl, cc, conj, root, det, obj, nmod, case, obl, case, nmod, punct]</td>\n      <td>[der, i, nat, mulm, og, mørke, forsvinde, en, del, mahogni, efter, stranding, i, fjor, ,]</td>\n      <td>[PartType=Inf, AdpType=Prep, Case=Gen|Definite=Def|Gender=Com|Number=Sing, Definite=Ind|Gender=Neut|Number=Sing, _, Definite=Ind|Gender=Neut|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, Definite=Ind|Number=Sing, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, AdpType=Prep, _, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[ADV, ADP, NOUN, NOUN, CCONJ, NOUN, VERB, DET, NOUN, NOUN, ADP, NOUN, ADP, NOUN, PUNCT]</td>\n      <td>train-v2-712\\n</td>\n      <td>der i nattens mulm og mørke forsvandt en del mahogni efter strandingen i fjor,\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]</td>\n      <td>[der, i, nattens, mulm, og, mørke, forsvandt, en, del, mahogni, efter, strandingen, i, fjor, ,]</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>[36, 3, 1, 1, 6, 1, 6, 6, 10, 6, 10, 13, 14, 11, 14, 18, 18, 14, 14, 21, 19, 14, 10, 26, 26, 10, 28, 26, 30, 26, 32, 30, 26, 36, 36, 0, 38, 36, 38, 52, 52, 52, 52, 52, 52, 48, 48, 52, 50, 52, 52, 36, 52, 36]</td>\n      <td>[nsubj, case, nmod, punct, det, appos, nmod, punct, nsubj, aux, advmod, amod, nmod, obj, flat, cc, nmod:poss, conj, amod, cc, conj, nmod:poss, punct, mark, nsubj, xcomp, case, obl, case, obl, cc, conj, punct, aux, advmod, root, case, obl, nmod:poss, cc, aux, advmod, xcomp, punct, mark, det, amod, nsubj, case, obl, aux, conj, advmod, punct]</td>\n      <td>[museum, i, Malacanang, ,, en, slags, rædselskabinet, ,, der, skulle, bekrive, afdød, præsident, Ferdinand, Marcos, og, hans, hustru, bizar, og, ekstravagant, livsstil, ,, da, de, sidde, ved, magt, i, 1960'er, og, 70'er, ,, være, nu, overtage, af, land, kulturfond, og, skulle, istedet, anskueliggøre, ,, hvad, den, filippinsk, nation, gennem, år, have, mestre, kulturelt, .]</td>\n      <td>[Definite=Def|Gender=Neut|Number=Sing, AdpType=Prep, _, _, Gender=Neut|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, Definite=Ind|Gender=Neut|Number=Sing, _, PartType=Inf, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, _, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, _, _, Number[psor]=Sing|Person=3|Poss=Yes|PronType=Prs, Case=Gen|Definite=Ind|Gender=Com|Number=Sing, Definite=Def|Degree=Pos|Number=Sing, _, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, _, _, Case=Nom|Number=Plur|Person=3|PronType=Prs, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, AdpType=Prep, Definite=Def|Gender=Com|Number=Sing, AdpType=Prep, Definite=Def|Gender=Com|Number=Plur, _, Definite=Def|Gender=Com|Number=Plur, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, AdpType=Prep, Case=Gen|Definite=Def|Gender=Neut|Number=Sing, Definite=Ind|Number=Sing, _, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, _, VerbForm=Inf|Voice=Act, _, Number=Sing|PronType=Int,Rel, Gender=Com|Number=Sing|PronType=Dem, Definite=Def|Degree=Pos|Number=Sing, Definite=Ind|Gender=Com|Number=Sing, AdpType=Prep, Definite=Def|Gender=Neut|Number=Plur, Mood=Ind|Tense=Pres|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Degree=Pos, _]</td>\n      <td>[O, O, B-LOC, O, O, O, O, O, O, O, O, O, O, B-PER, I-PER, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MISC, O, B-MISC, O, O, O, O, O, O, O, O, O, O, O, O, O, O, B-MISC, O, O, O, O, O, O, O]</td>\n      <td>[NOUN, ADP, PROPN, PUNCT, DET, NOUN, NOUN, PUNCT, PRON, AUX, X, ADJ, NOUN, PROPN, PROPN, CCONJ, PRON, NOUN, ADJ, CCONJ, ADJ, NOUN, PUNCT, SCONJ, PRON, VERB, ADP, NOUN, ADP, NOUN, CCONJ, NOUN, PUNCT, AUX, ADV, VERB, ADP, NOUN, NOUN, CCONJ, AUX, X, VERB, PUNCT, PRON, DET, ADJ, NOUN, ADP, NOUN, AUX, VERB, ADV, PUNCT]</td>\n      <td>train-v2-3456\\n</td>\n      <td>Museet i Malacanang, et slags rædselskabinet, der skulle bekrive afdøde præsident Ferdinand Marcos og hans hustrus bizarre og ekstravagante livsstil, da de sad ved magten i 1960'erne og 70'erne, er nu overtaget af landets Kulturfond og skal istedet anskueliggøre, hvad den filippinske nation gennem årene har mestret kulturelt.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54]</td>\n      <td>[Museet, i, Malacanang, ,, et, slags, rædselskabinet, ,, der, skulle, bekrive, afdøde, præsident, Ferdinand, Marcos, og, hans, hustrus, bizarre, og, ekstravagante, livsstil, ,, da, de, sad, ved, magten, i, 1960'erne, og, 70'erne, ,, er, nu, overtaget, af, landets, Kulturfond, og, skal, istedet, anskueliggøre, ,, hvad, den, filippinske, nation, gennem, årene, har, mestret, kulturelt, .]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>[14, 3, 1, 5, 3, 14, 14, 9, 14, 14, 14, 14, 14, 0, 18, 17, 18, 14, 21, 21, 14, 23, 24, 21, 24, 24, 30, 30, 30, 14, 30, 33, 30, 36, 36, 33, 36, 37, 14]</td>\n      <td>[nsubj, nsubj, acl:relcl, det, obj, aux, advmod, cop, obl, punct, nsubj, aux, advmod, root, det, advmod, amod, obj, case, det, obl, mark, nsubj, acl:relcl, advmod, punct, cc, aux, advmod, conj, obl:loc, case, obl, nsubj, aux, acl:relcl, amod, compound:prt, punct]</td>\n      <td>[det, der, ligne, en, flugt, have, ikke, være, flugt, ,, mand, have, blot, kaste, en, ret, ligegyldig, blik, mod, en, bil, hvis, motor, gå, ud, -, og, være, derpå, gå, videre, med, det, han, have, have, travlt, med, .]</td>\n      <td>[Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs, PartType=Inf, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, _, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Definite=Ind|Gender=Com|Number=Sing, _, Definite=Def|Gender=Com|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, _, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Gender=Neut|Number=Sing|PronType=Ind, _, Definite=Ind|Degree=Pos|Gender=Neut|Number=Sing, Definite=Ind|Gender=Neut|Number=Sing, AdpType=Prep, Gender=Com|Number=Sing|PronType=Ind, Definite=Ind|Gender=Com|Number=Sing, Case=Gen|PronType=Int,Rel, Definite=Ind|Gender=Com|Number=Sing, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, _, _, _, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, _, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, _, AdpType=Prep, Case=Acc|Gender=Neut|Number=Sing|Person=3|PronType=Prs, Case=Nom|Gender=Com|Number=Sing|Person=3|PronType=Prs, Mood=Ind|Tense=Past|VerbForm=Fin|Voice=Act, Definite=Ind|Number=Sing|Tense=Past|VerbForm=Part, Degree=Pos, AdpType=Prep, _]</td>\n      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n      <td>[PRON, ADV, VERB, DET, NOUN, AUX, ADV, AUX, NOUN, PUNCT, NOUN, AUX, ADV, VERB, DET, ADV, ADJ, NOUN, ADP, DET, NOUN, PRON, NOUN, VERB, ADV, PUNCT, CCONJ, AUX, ADV, VERB, ADV, ADP, PRON, PRON, AUX, VERB, ADV, ADP, PUNCT]</td>\n      <td>train-v2-260\\n</td>\n      <td>Det der lignede en flugt havde ikke været flugt, manden havde blot kastet et ret ligegyldigt blik mod en bil hvis motor gik ud - og var derpå gået videre med det han havde haft travlt med.\\n</td>\n      <td>[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]</td>\n      <td>[Det, der, lignede, en, flugt, havde, ikke, været, flugt, ,, manden, havde, blot, kastet, et, ret, ligegyldigt, blik, mod, en, bil, hvis, motor, gik, ud, -, og, var, derpå, gået, videre, med, det, han, havde, haft, travlt, med, .]</td>\n    </tr>\n  </tbody>\n</table>"
     },
     "metadata": {}
    }
   ],
   "source": [
    "show_random_elements(datasets[\"train\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n9qywopnIrJH"
   },
   "source": [
    "## Preprocessing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVx71GdAIrJH"
   },
   "source": [
    "Before we can feed those texts to our model, we need to preprocess them. This is done by a 🤗 Transformers `Tokenizer` which will (as the name indicates) tokenize the inputs (including converting the tokens to their corresponding IDs in the pretrained vocabulary) and put it in a format the model expects, as well as generate the other inputs that model requires.\n",
    "\n",
    "To do all of this, we instantiate our tokenizer with the `AutoTokenizer.from_pretrained` method, which will ensure:\n",
    "\n",
    "- we get a tokenizer that corresponds to the model architecture we want to use,\n",
    "- we download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "That vocabulary will be cached, so it's not downloaded again the next time we run the cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "eXNLu_-nIrJI"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "    \n",
    "tokenizer = AutoTokenizer.from_pretrained(model, do_lower_case=False, strip_accents = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl6IidfdIrJK"
   },
   "source": [
    "The following assertion ensures that our tokenizer is a fast tokenizers (backed by Rust) from the 🤗 Tokenizers library. Those fast tokenizers are available for almost all models, and we will need some of the special features they have for our preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "assert isinstance(tokenizer, transformers.PreTrainedTokenizerFast)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check which type of models have a fast tokenizer available and which don't on the [big table of models](https://huggingface.co/transformers/index.html#bigtable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rowT4iCLIrJK"
   },
   "source": [
    "You can directly call this tokenizer on one sentence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "a5hBlsrHIrJL",
    "outputId": "acdaa98a-a8cd-4a20-89b8-cc26437bbe90"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2914, 2390, 1931, 1944, 19054, 5, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "tokenizer(\"Hej dette er en sætning!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the model you selected, you will see different keys in the dictionary returned by the cell above. They don't matter much for what we're doing here (just know they are required by the model we will instantiate later), you can learn more about them in [this tutorial](https://huggingface.co/transformers/preprocessing.html) if you're interested.\n",
    "\n",
    "If, as is the case here, your inputs have already been split into words, you should pass the list of words to your tokenzier with the argument `is_split_into_words=True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2914, 16, 2390, 1931, 1944, 19054, 17270, 77, 2505, 18, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "tokenizer([\"Hej\", \",\", \"dette\", \"er\", \"en\", \"sætning\", \"opdelt\", \"i\", \"ord\", \".\"], is_split_into_words=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that transformers are often pretrained with subword tokenizers, meaning that even if your inputs have been split into words already, each of those words could be split again by the tokenizer. Let's look at an example of that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Hun', 'er', 'selv', 'på', 'femte', 'år', 'lykkeligt', 'gift', 'med', 'sin', 'socialdemokratiske', 'partifælle', ',', 'Mogens', 'Lykketoft', '.']\n"
     ]
    }
   ],
   "source": [
    "example = datasets[\"train\"][4]\n",
    "print(example[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['[CLS]', 'Hun', 'er', 'selv', 'på', 'femte', 'år', 'lykkeligt', 'gift', 'med', 'sin', 'socialdemokratiske', 'parti', '##f', '##ælle', ',', 'Mogens', 'Lykke', '##to', '##ft', '.', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "tokenized_input = tokenizer(example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the words \"Zwingmann\" and \"sheepmeat\" have been split in three subtokens.\n",
    "\n",
    "This means that we need to do some processing on our labels as the input ids returned by the tokenizer are longer than the lists of labels our dataset contain, first because some special tokens might be added (we can a `[CLS]` and a `[SEP]` above) and then because of those possible splits of words in multiple tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(16, 22)"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "len(example[f\"ner_tags\"]), len(tokenized_input[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thankfully, the tokenizer returns outputs that have a `word_ids` method which can help us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[None, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 11, 11, 12, 13, 14, 14, 14, 15, None]\n"
     ]
    }
   ],
   "source": [
    "print(tokenized_input.word_ids())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, it returns a list with the same number of elements as our processed input ids, mapping special tokens to `None` and all other tokens to their respective word. This way, we can align the labels with the processed input ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "22 22\n"
     ]
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "aligned_labels = [-100 if i is None else example[f\"ner_tags\"][i] for i in word_ids]\n",
    "print(len(aligned_labels), len(tokenized_input[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we set the labels of all special tokens to -100 (the index that is ignored by PyTorch) and the labels of all other tokens to the label of the word they come from. Another strategy is to set the label only on the first token obtained from a given word, and give a label of -100 to the other subtokens from the same word. We propose the two strategies here, just change the value of the following flag:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_all_tokens = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C0hcmp9IrJQ"
   },
   "source": [
    "We're now ready to write the function that will preprocess our samples. We feed them to the `tokenizer` with the argument `truncation=True` (to truncate texts that are bigger than the maximum size allowed by the model) and `is_split_into_words=True` (as seen above). Then we align the labels with the token ids using the strategy we picked:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "vc0BSBLIIrJQ"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
    "\n",
    "    labels = []\n",
    "    for i, label in enumerate(examples[f\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            # Special tokens have a word id that is None. We set the label to -100 so they are automatically\n",
    "            # ignored in the loss function.\n",
    "            if word_idx is None:\n",
    "                label_ids.append(-100)\n",
    "            # We set the label for the first token of each word.\n",
    "            elif word_idx != previous_word_idx:\n",
    "                label_ids.append(label[word_idx])\n",
    "            # For the other tokens in a word, we set the label to either the current label or -100, depending on\n",
    "            # the label_all_tokens flag.\n",
    "            else:\n",
    "                label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
    "            previous_word_idx = word_idx\n",
    "\n",
    "        labels.append(label_ids)\n",
    "\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lm8ozrJIrJR"
   },
   "source": [
    "This function works with one or several examples. In the case of several examples, the tokenizer will return a list of lists for each key:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "-b70jh26IrJS",
    "outputId": "acd3a42d-985b-44ee-9daa-af5d944ce1d9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 2892, 7344, 1968, 21277, 1035, 15218, 1939, 13297, 1992, 77, 21277, 1035, 17, 6086, 77, 5752, 1937, 1934, 11245, 29800, 10214, 2423, 1999, 77, 1966, 7298, 3071, 6832, 1010, 18, 3], [2, 3767, 3481, 1926, 2204, 13765, 1926, 10668, 77, 2265, 2029, 3094, 4528, 16, 1981, 1944, 3908, 22864, 1940, 18, 3], [2, 3541, 7118, 1926, 4264, 77, 5986, 3832, 30090, 1926, 24415, 1956, 18, 3], [2, 8695, 1940, 10240, 7001, 4490, 2809, 15509, 2201, 1962, 1956, 2852, 17, 16556, 1010, 5911, 1027, 1968, 2161, 3071, 17, 1926, 8075, 8216, 1931, 1987, 3676, 1927, 2552, 2546, 13703, 16, 1934, 1963, 1968, 3137, 23388, 1926, 6424, 16016, 2123, 18, 3], [2, 2555, 1931, 2161, 1955, 15556, 2143, 28528, 4988, 1956, 2429, 22703, 8562, 1049, 3701, 16, 17997, 13706, 7265, 2048, 18, 3]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]], 'labels': [[-100, 0, 0, 0, 3, 3, 0, 0, 0, 0, 0, 5, 5, 5, 5, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, -100], [-100, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 1, 2, 2, 2, 0, -100]]}"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "tokenize_and_align_labels(datasets['train'][:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zS-6iXTkIrJT"
   },
   "source": [
    "To apply this function on all the sentences (or pairs of sentences) in our dataset, we just use the `map` method of our `dataset` object we created earlier. This will apply the function on all the elements of all the splits in `dataset`, so our training, validation and testing data will be preprocessed in one single command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DDtsaJeVIrJT",
    "outputId": "aa4734bf-4ef5-4437-9948-2c16363da719"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Loading cached processed dataset at C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6\\cache-9d9cc0e513a632a3.arrow\n",
      "Loading cached processed dataset at C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6\\cache-bf2d64edcf1ef7fa.arrow\n",
      "Loading cached processed dataset at C:\\Users\\z6hjb\\.cache\\huggingface\\datasets\\dane\\default\\0.0.0\\5321342ee0a282c6958fe4151e728b84949f0dd70decbf736633c240300a65f6\\cache-1341493b0c81719d.arrow\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = datasets.map(tokenize_and_align_labels, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "voWiw8C7IrJV"
   },
   "source": [
    "Even better, the results are automatically cached by the 🤗 Datasets library to avoid spending time on this step the next time you run your notebook. The 🤗 Datasets library is normally smart enough to detect when the function you pass to map has changed (and thus requires to not use the cache data). For instance, it will properly detect if you change the task in the first cell and rerun the notebook. 🤗 Datasets warns you when it uses cached files, you can pass `load_from_cache_file=False` in the call to `map` to not use the cached files and force the preprocessing to be applied again.\n",
    "\n",
    "Note that we passed `batched=True` to encode the texts by batches together. This is to leverage the full benefit of the fast tokenizer we loaded earlier, which will use multi-threading to treat the texts in a batch concurrently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "545PP3o8IrJV"
   },
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBiW8UpKIrJW"
   },
   "source": [
    "Now that our data is ready, we can download the pretrained model and fine-tune it. Since all our tasks are about token classification, we use the `AutoModelForTokenClassification` class. Like with the tokenizer, the `from_pretrained` method will download and cache the model for us. The only thing we have to specify is the number of labels for our problem (which we can get from the features, as seen before):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "id": "TlqNaB8jIrJW",
    "outputId": "84916cf3-6e6c-47f3-d081-032ec30a4132",
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Some weights of the model checkpoint at Maltehb/-l-ctra-danish-electra-small-cased were not used when initializing ElectraForTokenClassification: ['generator.embeddings.word_embeddings.weight', 'generator.embeddings.position_embeddings.weight', 'generator.embeddings.token_type_embeddings.weight', 'generator.embeddings.LayerNorm.weight', 'generator.embeddings.LayerNorm.bias', 'generator.encoder.layer.0.attention.self.query.weight', 'generator.encoder.layer.0.attention.self.query.bias', 'generator.encoder.layer.0.attention.self.key.weight', 'generator.encoder.layer.0.attention.self.key.bias', 'generator.encoder.layer.0.attention.self.value.weight', 'generator.encoder.layer.0.attention.self.value.bias', 'generator.encoder.layer.0.attention.output.dense.weight', 'generator.encoder.layer.0.attention.output.dense.bias', 'generator.encoder.layer.0.attention.output.LayerNorm.weight', 'generator.encoder.layer.0.attention.output.LayerNorm.bias', 'generator.encoder.layer.0.intermediate.dense.weight', 'generator.encoder.layer.0.intermediate.dense.bias', 'generator.encoder.layer.0.output.dense.weight', 'generator.encoder.layer.0.output.dense.bias', 'generator.encoder.layer.0.output.LayerNorm.weight', 'generator.encoder.layer.0.output.LayerNorm.bias', 'generator.encoder.layer.1.attention.self.query.weight', 'generator.encoder.layer.1.attention.self.query.bias', 'generator.encoder.layer.1.attention.self.key.weight', 'generator.encoder.layer.1.attention.self.key.bias', 'generator.encoder.layer.1.attention.self.value.weight', 'generator.encoder.layer.1.attention.self.value.bias', 'generator.encoder.layer.1.attention.output.dense.weight', 'generator.encoder.layer.1.attention.output.dense.bias', 'generator.encoder.layer.1.attention.output.LayerNorm.weight', 'generator.encoder.layer.1.attention.output.LayerNorm.bias', 'generator.encoder.layer.1.intermediate.dense.weight', 'generator.encoder.layer.1.intermediate.dense.bias', 'generator.encoder.layer.1.output.dense.weight', 'generator.encoder.layer.1.output.dense.bias', 'generator.encoder.layer.1.output.LayerNorm.weight', 'generator.encoder.layer.1.output.LayerNorm.bias', 'generator.encoder.layer.2.attention.self.query.weight', 'generator.encoder.layer.2.attention.self.query.bias', 'generator.encoder.layer.2.attention.self.key.weight', 'generator.encoder.layer.2.attention.self.key.bias', 'generator.encoder.layer.2.attention.self.value.weight', 'generator.encoder.layer.2.attention.self.value.bias', 'generator.encoder.layer.2.attention.output.dense.weight', 'generator.encoder.layer.2.attention.output.dense.bias', 'generator.encoder.layer.2.attention.output.LayerNorm.weight', 'generator.encoder.layer.2.attention.output.LayerNorm.bias', 'generator.encoder.layer.2.intermediate.dense.weight', 'generator.encoder.layer.2.intermediate.dense.bias', 'generator.encoder.layer.2.output.dense.weight', 'generator.encoder.layer.2.output.dense.bias', 'generator.encoder.layer.2.output.LayerNorm.weight', 'generator.encoder.layer.2.output.LayerNorm.bias', 'generator.encoder.layer.3.attention.self.query.weight', 'generator.encoder.layer.3.attention.self.query.bias', 'generator.encoder.layer.3.attention.self.key.weight', 'generator.encoder.layer.3.attention.self.key.bias', 'generator.encoder.layer.3.attention.self.value.weight', 'generator.encoder.layer.3.attention.self.value.bias', 'generator.encoder.layer.3.attention.output.dense.weight', 'generator.encoder.layer.3.attention.output.dense.bias', 'generator.encoder.layer.3.attention.output.LayerNorm.weight', 'generator.encoder.layer.3.attention.output.LayerNorm.bias', 'generator.encoder.layer.3.intermediate.dense.weight', 'generator.encoder.layer.3.intermediate.dense.bias', 'generator.encoder.layer.3.output.dense.weight', 'generator.encoder.layer.3.output.dense.bias', 'generator.encoder.layer.3.output.LayerNorm.weight', 'generator.encoder.layer.3.output.LayerNorm.bias', 'generator.encoder.layer.4.attention.self.query.weight', 'generator.encoder.layer.4.attention.self.query.bias', 'generator.encoder.layer.4.attention.self.key.weight', 'generator.encoder.layer.4.attention.self.key.bias', 'generator.encoder.layer.4.attention.self.value.weight', 'generator.encoder.layer.4.attention.self.value.bias', 'generator.encoder.layer.4.attention.output.dense.weight', 'generator.encoder.layer.4.attention.output.dense.bias', 'generator.encoder.layer.4.attention.output.LayerNorm.weight', 'generator.encoder.layer.4.attention.output.LayerNorm.bias', 'generator.encoder.layer.4.intermediate.dense.weight', 'generator.encoder.layer.4.intermediate.dense.bias', 'generator.encoder.layer.4.output.dense.weight', 'generator.encoder.layer.4.output.dense.bias', 'generator.encoder.layer.4.output.LayerNorm.weight', 'generator.encoder.layer.4.output.LayerNorm.bias', 'generator.encoder.layer.5.attention.self.query.weight', 'generator.encoder.layer.5.attention.self.query.bias', 'generator.encoder.layer.5.attention.self.key.weight', 'generator.encoder.layer.5.attention.self.key.bias', 'generator.encoder.layer.5.attention.self.value.weight', 'generator.encoder.layer.5.attention.self.value.bias', 'generator.encoder.layer.5.attention.output.dense.weight', 'generator.encoder.layer.5.attention.output.dense.bias', 'generator.encoder.layer.5.attention.output.LayerNorm.weight', 'generator.encoder.layer.5.attention.output.LayerNorm.bias', 'generator.encoder.layer.5.intermediate.dense.weight', 'generator.encoder.layer.5.intermediate.dense.bias', 'generator.encoder.layer.5.output.dense.weight', 'generator.encoder.layer.5.output.dense.bias', 'generator.encoder.layer.5.output.LayerNorm.weight', 'generator.encoder.layer.5.output.LayerNorm.bias', 'generator.encoder.layer.6.attention.self.query.weight', 'generator.encoder.layer.6.attention.self.query.bias', 'generator.encoder.layer.6.attention.self.key.weight', 'generator.encoder.layer.6.attention.self.key.bias', 'generator.encoder.layer.6.attention.self.value.weight', 'generator.encoder.layer.6.attention.self.value.bias', 'generator.encoder.layer.6.attention.output.dense.weight', 'generator.encoder.layer.6.attention.output.dense.bias', 'generator.encoder.layer.6.attention.output.LayerNorm.weight', 'generator.encoder.layer.6.attention.output.LayerNorm.bias', 'generator.encoder.layer.6.intermediate.dense.weight', 'generator.encoder.layer.6.intermediate.dense.bias', 'generator.encoder.layer.6.output.dense.weight', 'generator.encoder.layer.6.output.dense.bias', 'generator.encoder.layer.6.output.LayerNorm.weight', 'generator.encoder.layer.6.output.LayerNorm.bias', 'generator.encoder.layer.7.attention.self.query.weight', 'generator.encoder.layer.7.attention.self.query.bias', 'generator.encoder.layer.7.attention.self.key.weight', 'generator.encoder.layer.7.attention.self.key.bias', 'generator.encoder.layer.7.attention.self.value.weight', 'generator.encoder.layer.7.attention.self.value.bias', 'generator.encoder.layer.7.attention.output.dense.weight', 'generator.encoder.layer.7.attention.output.dense.bias', 'generator.encoder.layer.7.attention.output.LayerNorm.weight', 'generator.encoder.layer.7.attention.output.LayerNorm.bias', 'generator.encoder.layer.7.intermediate.dense.weight', 'generator.encoder.layer.7.intermediate.dense.bias', 'generator.encoder.layer.7.output.dense.weight', 'generator.encoder.layer.7.output.dense.bias', 'generator.encoder.layer.7.output.LayerNorm.weight', 'generator.encoder.layer.7.output.LayerNorm.bias', 'generator.encoder.layer.8.attention.self.query.weight', 'generator.encoder.layer.8.attention.self.query.bias', 'generator.encoder.layer.8.attention.self.key.weight', 'generator.encoder.layer.8.attention.self.key.bias', 'generator.encoder.layer.8.attention.self.value.weight', 'generator.encoder.layer.8.attention.self.value.bias', 'generator.encoder.layer.8.attention.output.dense.weight', 'generator.encoder.layer.8.attention.output.dense.bias', 'generator.encoder.layer.8.attention.output.LayerNorm.weight', 'generator.encoder.layer.8.attention.output.LayerNorm.bias', 'generator.encoder.layer.8.intermediate.dense.weight', 'generator.encoder.layer.8.intermediate.dense.bias', 'generator.encoder.layer.8.output.dense.weight', 'generator.encoder.layer.8.output.dense.bias', 'generator.encoder.layer.8.output.LayerNorm.weight', 'generator.encoder.layer.8.output.LayerNorm.bias', 'generator.encoder.layer.9.attention.self.query.weight', 'generator.encoder.layer.9.attention.self.query.bias', 'generator.encoder.layer.9.attention.self.key.weight', 'generator.encoder.layer.9.attention.self.key.bias', 'generator.encoder.layer.9.attention.self.value.weight', 'generator.encoder.layer.9.attention.self.value.bias', 'generator.encoder.layer.9.attention.output.dense.weight', 'generator.encoder.layer.9.attention.output.dense.bias', 'generator.encoder.layer.9.attention.output.LayerNorm.weight', 'generator.encoder.layer.9.attention.output.LayerNorm.bias', 'generator.encoder.layer.9.intermediate.dense.weight', 'generator.encoder.layer.9.intermediate.dense.bias', 'generator.encoder.layer.9.output.dense.weight', 'generator.encoder.layer.9.output.dense.bias', 'generator.encoder.layer.9.output.LayerNorm.weight', 'generator.encoder.layer.9.output.LayerNorm.bias', 'generator.encoder.layer.10.attention.self.query.weight', 'generator.encoder.layer.10.attention.self.query.bias', 'generator.encoder.layer.10.attention.self.key.weight', 'generator.encoder.layer.10.attention.self.key.bias', 'generator.encoder.layer.10.attention.self.value.weight', 'generator.encoder.layer.10.attention.self.value.bias', 'generator.encoder.layer.10.attention.output.dense.weight', 'generator.encoder.layer.10.attention.output.dense.bias', 'generator.encoder.layer.10.attention.output.LayerNorm.weight', 'generator.encoder.layer.10.attention.output.LayerNorm.bias', 'generator.encoder.layer.10.intermediate.dense.weight', 'generator.encoder.layer.10.intermediate.dense.bias', 'generator.encoder.layer.10.output.dense.weight', 'generator.encoder.layer.10.output.dense.bias', 'generator.encoder.layer.10.output.LayerNorm.weight', 'generator.encoder.layer.10.output.LayerNorm.bias', 'generator.encoder.layer.11.attention.self.query.weight', 'generator.encoder.layer.11.attention.self.query.bias', 'generator.encoder.layer.11.attention.self.key.weight', 'generator.encoder.layer.11.attention.self.key.bias', 'generator.encoder.layer.11.attention.self.value.weight', 'generator.encoder.layer.11.attention.self.value.bias', 'generator.encoder.layer.11.attention.output.dense.weight', 'generator.encoder.layer.11.attention.output.dense.bias', 'generator.encoder.layer.11.attention.output.LayerNorm.weight', 'generator.encoder.layer.11.attention.output.LayerNorm.bias', 'generator.encoder.layer.11.intermediate.dense.weight', 'generator.encoder.layer.11.intermediate.dense.bias', 'generator.encoder.layer.11.output.dense.weight', 'generator.encoder.layer.11.output.dense.bias', 'generator.encoder.layer.11.output.LayerNorm.weight', 'generator.encoder.layer.11.output.LayerNorm.bias', 'generator.embeddings_project.weight', 'generator.embeddings_project.bias', 'generator_predictions.bias', 'generator_predictions.dense.weight', 'generator_predictions.dense.bias', 'generator_predictions.LayerNorm.weight', 'generator_predictions.LayerNorm.bias', 'generator_predictions.decoder.weight', 'generator_predictions.decoder.bias', 'discriminator_predictions.dense.weight', 'discriminator_predictions.dense.bias', 'discriminator_predictions.LayerNorm.weight', 'discriminator_predictions.LayerNorm.bias', 'discriminator_predictions.classifier.weight', 'discriminator_predictions.classifier.bias']\n",
      "- This IS expected if you are initializing ElectraForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForTokenClassification were not initialized from the model checkpoint at Maltehb/-l-ctra-danish-electra-small-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(model, num_labels=len(label_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CczA5lJlIrJX"
   },
   "source": [
    "The warning is telling us we are throwing away some weights (the `vocab_transform` and `vocab_layer_norm` layers) and randomly initializing some other (the `pre_classifier` and `classifier` layers). This is absolutely normal in this case, because we are removing the head used to pretrain the model on a masked language modeling objective and replacing it with a new head for which we don't have pretrained weights, so the library warns us we should fine-tune this model before using it for inference, which is exactly what we are going to do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_N8urzhyIrJY"
   },
   "source": [
    "To instantiate a `Trainer`, we will need to define three more things. The most important is the [`TrainingArguments`](https://huggingface.co/transformers/main_classes/trainer.html#transformers.TrainingArguments), which is a class that contains all the attributes to customize the training. It requires one folder name, which will be used to save the checkpoints of the model, and all other arguments are optional:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "Bliy8zgjIrJY"
   },
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    f\"test-ner\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=3e-5,\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    num_train_epochs=8,\n",
    "    weight_decay=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "km3pGVdTIrJc"
   },
   "source": [
    "Here we set the evaluation to be done at the end of each epoch, tweak the learning rate, use the `batch_size` defined at the top of the notebook and customize the number of epochs for training, as well as the weight decay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we will need a data collator that will batch our processed examples together while applying padding to make them all the same size (each pad will be padded to the length of its longest example). There is a data collator for this task in the Transformers library, that not only pads the inputs, but also the labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last thing to define for our `Trainer` is how to compute the metrics from the predictions. Here we will load the [`seqeval`](https://github.com/chakki-works/seqeval) metric (which is commonly used to evaluate results on the CONLL dataset) via the Datasets library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = load_metric(\"seqeval\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This metric takes list of labels for the predictions and references:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'MISC': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'PER': {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'number': 1},\n",
       " 'overall_precision': 1.0,\n",
       " 'overall_recall': 1.0,\n",
       " 'overall_f1': 1.0,\n",
       " 'overall_accuracy': 1.0}"
      ]
     },
     "metadata": {},
     "execution_count": 55
    }
   ],
   "source": [
    "labels = [label_list[i] for i in example[f\"ner_tags\"]]\n",
    "metric.compute(predictions=[labels], references=[labels])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7sZOdRlRIrJd"
   },
   "source": [
    "So we will need to do a bit of post-processing on our predictions:\n",
    "- select the predicted index (with the maximum logit) for each token\n",
    "- convert it to its string label\n",
    "- ignore everywhere we set a label of -100\n",
    "\n",
    "The following function does all this post-processing on the result of `Trainer.evaluate` (which is a namedtuple containing predictions and labels) before applying the metric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "id": "UmvbnJ9JIrJd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "    # Remove ignored index (special tokens)\n",
    "    true_predictions = [\n",
    "        [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    true_labels = [\n",
    "        [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "\n",
    "    results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rXuFTAzDIrJe"
   },
   "source": [
    "Note that we drop the precision/recall/f1 computed for each category and only focus on the overall precision/recall/f1/accuracy.\n",
    "\n",
    "Then we just need to pass all of this along with our datasets to the `Trainer`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "imY1oC3SIrJf"
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    eval_dataset=tokenized_datasets[\"validation\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CdzABDVcIrJg"
   },
   "source": [
    "We can now finetune our model by just calling the `train` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "██████▎| 4067/4384 [23:20<01:28,  3.60it/s]\u001b[A\n",
      " 93%|█████████▎| 4068/4384 [23:20<01:36,  3.27it/s]\u001b[A\n",
      " 93%|█████████▎| 4069/4384 [23:20<01:33,  3.37it/s]\u001b[A\n",
      " 93%|█████████▎| 4070/4384 [23:21<01:35,  3.28it/s]\u001b[A\n",
      " 93%|█████████▎| 4071/4384 [23:21<01:35,  3.27it/s]\u001b[A\n",
      " 93%|█████████▎| 4072/4384 [23:21<01:39,  3.13it/s]\u001b[A\n",
      " 93%|█████████▎| 4073/4384 [23:22<01:38,  3.16it/s]\u001b[A\n",
      " 93%|█████████▎| 4074/4384 [23:22<01:33,  3.32it/s]\u001b[A\n",
      " 93%|█████████▎| 4075/4384 [23:22<01:40,  3.08it/s]\u001b[A\n",
      " 93%|█████████▎| 4076/4384 [23:23<01:34,  3.25it/s]\u001b[A\n",
      " 93%|█████████▎| 4077/4384 [23:23<01:25,  3.60it/s]\u001b[A\n",
      " 93%|█████████▎| 4078/4384 [23:23<01:21,  3.77it/s]\u001b[A\n",
      " 93%|█████████▎| 4079/4384 [23:23<01:24,  3.62it/s]\u001b[A\n",
      " 93%|█████████▎| 4080/4384 [23:24<01:25,  3.54it/s]\u001b[A\n",
      " 93%|█████████▎| 4081/4384 [23:24<01:31,  3.30it/s]\u001b[A\n",
      " 93%|█████████▎| 4082/4384 [23:24<01:28,  3.42it/s]\u001b[A\n",
      " 93%|█████████▎| 4083/4384 [23:24<01:23,  3.62it/s]\u001b[A\n",
      " 93%|█████████▎| 4084/4384 [23:25<01:25,  3.50it/s]\u001b[A\n",
      " 93%|█████████▎| 4085/4384 [23:25<01:21,  3.67it/s]\u001b[A\n",
      " 93%|█████████▎| 4086/4384 [23:25<01:18,  3.81it/s]\u001b[A\n",
      " 93%|█████████▎| 4087/4384 [23:25<01:18,  3.77it/s]\u001b[A\n",
      " 93%|█████████▎| 4088/4384 [23:26<01:19,  3.70it/s]\u001b[A\n",
      " 93%|█████████▎| 4089/4384 [23:26<01:18,  3.77it/s]\u001b[A\n",
      " 93%|█████████▎| 4090/4384 [23:26<01:14,  3.97it/s]\u001b[A\n",
      " 93%|█████████▎| 4091/4384 [23:26<01:13,  3.96it/s]\u001b[A\n",
      " 93%|█████████▎| 4092/4384 [23:27<01:13,  3.96it/s]\u001b[A\n",
      " 93%|█████████▎| 4093/4384 [23:27<01:14,  3.89it/s]\u001b[A\n",
      " 93%|█████████▎| 4094/4384 [23:27<01:16,  3.81it/s]\u001b[A\n",
      " 93%|█████████▎| 4095/4384 [23:28<01:14,  3.90it/s]\u001b[A\n",
      " 93%|█████████▎| 4096/4384 [23:28<01:12,  3.99it/s]\u001b[A\n",
      " 93%|█████████▎| 4097/4384 [23:28<01:17,  3.72it/s]\u001b[A\n",
      " 93%|█████████▎| 4098/4384 [23:28<01:14,  3.84it/s]\u001b[A\n",
      " 93%|█████████▎| 4099/4384 [23:29<01:19,  3.56it/s]\u001b[A\n",
      " 94%|█████████▎| 4100/4384 [23:29<01:15,  3.74it/s]\u001b[A\n",
      " 94%|█████████▎| 4101/4384 [23:29<01:19,  3.57it/s]\u001b[A\n",
      " 94%|█████████▎| 4102/4384 [23:29<01:14,  3.77it/s]\u001b[A\n",
      " 94%|█████████▎| 4103/4384 [23:30<01:15,  3.72it/s]\u001b[A\n",
      " 94%|█████████▎| 4104/4384 [23:30<01:19,  3.53it/s]\u001b[A\n",
      " 94%|█████████▎| 4105/4384 [23:30<01:17,  3.58it/s]\u001b[A\n",
      " 94%|█████████▎| 4106/4384 [23:31<01:17,  3.61it/s]\u001b[A\n",
      " 94%|█████████▎| 4107/4384 [23:31<01:13,  3.78it/s]\u001b[A\n",
      " 94%|█████████▎| 4108/4384 [23:31<01:14,  3.73it/s]\u001b[A\n",
      " 94%|█████████▎| 4109/4384 [23:31<01:20,  3.41it/s]\u001b[A\n",
      " 94%|█████████▍| 4110/4384 [23:32<01:17,  3.55it/s]\u001b[A\n",
      " 94%|█████████▍| 4111/4384 [23:32<01:15,  3.62it/s]\u001b[A\n",
      " 94%|█████████▍| 4112/4384 [23:32<01:19,  3.44it/s]\u001b[A\n",
      " 94%|█████████▍| 4113/4384 [23:33<01:22,  3.27it/s]\u001b[A\n",
      " 94%|█████████▍| 4114/4384 [23:33<01:25,  3.17it/s]\u001b[A\n",
      " 94%|█████████▍| 4115/4384 [23:33<01:20,  3.32it/s]\u001b[A\n",
      " 94%|█████████▍| 4116/4384 [23:34<01:23,  3.20it/s]\u001b[A\n",
      " 94%|█████████▍| 4117/4384 [23:34<01:18,  3.40it/s]\u001b[A\n",
      " 94%|█████████▍| 4118/4384 [23:34<01:20,  3.29it/s]\u001b[A\n",
      " 94%|█████████▍| 4119/4384 [23:34<01:19,  3.33it/s]\u001b[A\n",
      " 94%|█████████▍| 4120/4384 [23:35<01:17,  3.40it/s]\u001b[A\n",
      " 94%|█████████▍| 4121/4384 [23:35<01:15,  3.46it/s]\u001b[A\n",
      " 94%|█████████▍| 4122/4384 [23:35<01:12,  3.61it/s]\u001b[A\n",
      " 94%|█████████▍| 4123/4384 [23:36<01:12,  3.58it/s]\u001b[A\n",
      " 94%|█████████▍| 4124/4384 [23:36<01:07,  3.85it/s]\u001b[A\n",
      " 94%|█████████▍| 4125/4384 [23:36<01:08,  3.76it/s]\u001b[A\n",
      " 94%|█████████▍| 4126/4384 [23:36<01:12,  3.56it/s]\u001b[A\n",
      " 94%|█████████▍| 4127/4384 [23:37<01:15,  3.40it/s]\u001b[A\n",
      " 94%|█████████▍| 4128/4384 [23:37<01:15,  3.38it/s]\u001b[A\n",
      " 94%|█████████▍| 4129/4384 [23:37<01:16,  3.35it/s]\u001b[A\n",
      " 94%|█████████▍| 4130/4384 [23:37<01:11,  3.53it/s]\u001b[A\n",
      " 94%|█████████▍| 4131/4384 [23:38<01:10,  3.58it/s]\u001b[A\n",
      " 94%|█████████▍| 4132/4384 [23:38<01:07,  3.71it/s]\u001b[A\n",
      " 94%|█████████▍| 4133/4384 [23:38<01:09,  3.63it/s]\u001b[A\n",
      " 94%|█████████▍| 4134/4384 [23:39<01:07,  3.71it/s]\u001b[A\n",
      " 94%|█████████▍| 4135/4384 [23:39<01:08,  3.65it/s]\u001b[A\n",
      " 94%|█████████▍| 4136/4384 [23:39<01:04,  3.85it/s]\u001b[A\n",
      " 94%|█████████▍| 4137/4384 [23:39<01:11,  3.44it/s]\u001b[A\n",
      " 94%|█████████▍| 4138/4384 [23:40<01:17,  3.19it/s]\u001b[A\n",
      " 94%|█████████▍| 4139/4384 [23:40<01:12,  3.36it/s]\u001b[A\n",
      " 94%|█████████▍| 4140/4384 [23:40<01:11,  3.41it/s]\u001b[A\n",
      " 94%|█████████▍| 4141/4384 [23:41<01:18,  3.08it/s]\u001b[A\n",
      " 94%|█████████▍| 4142/4384 [23:41<01:14,  3.27it/s]\u001b[A\n",
      " 95%|█████████▍| 4143/4384 [23:41<01:11,  3.37it/s]\u001b[A\n",
      " 95%|█████████▍| 4144/4384 [23:42<01:06,  3.59it/s]\u001b[A\n",
      " 95%|█████████▍| 4145/4384 [23:42<01:08,  3.49it/s]\u001b[A\n",
      " 95%|█████████▍| 4146/4384 [23:42<01:12,  3.28it/s]\u001b[A\n",
      " 95%|█████████▍| 4147/4384 [23:43<01:29,  2.63it/s]\u001b[A\n",
      " 95%|█████████▍| 4148/4384 [23:43<01:26,  2.74it/s]\u001b[A\n",
      " 95%|█████████▍| 4149/4384 [23:43<01:15,  3.11it/s]\u001b[A\n",
      " 95%|█████████▍| 4150/4384 [23:43<01:09,  3.39it/s]\u001b[A\n",
      " 95%|█████████▍| 4151/4384 [23:44<01:08,  3.40it/s]\u001b[A\n",
      " 95%|█████████▍| 4152/4384 [23:44<01:04,  3.62it/s]\u001b[A\n",
      " 95%|█████████▍| 4153/4384 [23:44<01:00,  3.81it/s]\u001b[A\n",
      " 95%|█████████▍| 4154/4384 [23:45<01:03,  3.64it/s]\u001b[A\n",
      " 95%|█████████▍| 4155/4384 [23:45<00:59,  3.83it/s]\u001b[A\n",
      " 95%|█████████▍| 4156/4384 [23:45<01:06,  3.42it/s]\u001b[A\n",
      " 95%|█████████▍| 4157/4384 [23:45<01:06,  3.40it/s]\u001b[A\n",
      " 95%|█████████▍| 4158/4384 [23:46<01:04,  3.50it/s]\u001b[A\n",
      " 95%|█████████▍| 4159/4384 [23:46<01:04,  3.51it/s]\u001b[A\n",
      " 95%|█████████▍| 4160/4384 [23:46<01:10,  3.19it/s]\u001b[A\n",
      " 95%|█████████▍| 4161/4384 [23:47<01:15,  2.97it/s]\u001b[A\n",
      " 95%|█████████▍| 4162/4384 [23:47<01:11,  3.12it/s]\u001b[A\n",
      " 95%|█████████▍| 4163/4384 [23:47<01:06,  3.32it/s]\u001b[A\n",
      " 95%|█████████▍| 4164/4384 [23:48<01:02,  3.55it/s]\u001b[A\n",
      " 95%|█████████▌| 4165/4384 [23:48<00:55,  3.95it/s]\u001b[A\n",
      " 95%|█████████▌| 4166/4384 [23:48<00:55,  3.92it/s]\u001b[A\n",
      " 95%|█████████▌| 4167/4384 [23:48<01:09,  3.12it/s]\u001b[A\n",
      " 95%|█████████▌| 4168/4384 [23:49<01:02,  3.43it/s]\u001b[A\n",
      " 95%|█████████▌| 4169/4384 [23:49<01:00,  3.54it/s]\u001b[A\n",
      " 95%|█████████▌| 4170/4384 [23:49<01:01,  3.48it/s]\u001b[A\n",
      " 95%|█████████▌| 4171/4384 [23:50<00:59,  3.59it/s]\u001b[A\n",
      " 95%|█████████▌| 4172/4384 [23:50<01:00,  3.53it/s]\u001b[A\n",
      " 95%|█████████▌| 4173/4384 [23:50<01:04,  3.30it/s]\u001b[A\n",
      " 95%|█████████▌| 4174/4384 [23:50<01:06,  3.18it/s]\u001b[A\n",
      " 95%|█████████▌| 4175/4384 [23:51<00:57,  3.64it/s]\u001b[A\n",
      " 95%|█████████▌| 4176/4384 [23:51<00:55,  3.77it/s]\u001b[A\n",
      " 95%|█████████▌| 4177/4384 [23:51<00:56,  3.65it/s]\u001b[A\n",
      " 95%|█████████▌| 4178/4384 [23:51<00:54,  3.81it/s]\u001b[A\n",
      " 95%|█████████▌| 4179/4384 [23:52<00:52,  3.87it/s]\u001b[A\n",
      " 95%|█████████▌| 4180/4384 [23:52<00:53,  3.85it/s]\u001b[A\n",
      " 95%|█████████▌| 4181/4384 [23:52<01:06,  3.06it/s]\u001b[A\n",
      " 95%|█████████▌| 4182/4384 [23:53<01:01,  3.30it/s]\u001b[A\n",
      " 95%|█████████▌| 4183/4384 [23:53<01:00,  3.30it/s]\u001b[A\n",
      " 95%|█████████▌| 4184/4384 [23:53<00:59,  3.36it/s]\u001b[A\n",
      " 95%|█████████▌| 4185/4384 [23:54<00:57,  3.47it/s]\u001b[A\n",
      " 95%|█████████▌| 4186/4384 [23:54<00:56,  3.52it/s]\u001b[A\n",
      " 96%|█████████▌| 4187/4384 [23:54<00:55,  3.54it/s]\u001b[A\n",
      " 96%|█████████▌| 4188/4384 [23:54<00:56,  3.48it/s]\u001b[A\n",
      " 96%|█████████▌| 4189/4384 [23:55<00:51,  3.78it/s]\u001b[A\n",
      " 96%|█████████▌| 4190/4384 [23:55<00:52,  3.73it/s]\u001b[A\n",
      " 96%|█████████▌| 4191/4384 [23:55<00:50,  3.84it/s]\u001b[A\n",
      " 96%|█████████▌| 4192/4384 [23:55<00:52,  3.63it/s]\u001b[A\n",
      " 96%|█████████▌| 4193/4384 [23:56<00:52,  3.66it/s]\u001b[A\n",
      " 96%|█████████▌| 4194/4384 [23:56<00:47,  3.98it/s]\u001b[A\n",
      " 96%|█████████▌| 4195/4384 [23:56<00:50,  3.77it/s]\u001b[A\n",
      " 96%|█████████▌| 4196/4384 [23:56<00:49,  3.83it/s]\u001b[A\n",
      " 96%|█████████▌| 4197/4384 [23:57<01:01,  3.03it/s]\u001b[A\n",
      " 96%|█████████▌| 4198/4384 [23:57<01:05,  2.86it/s]\u001b[A\n",
      " 96%|█████████▌| 4199/4384 [23:58<01:04,  2.86it/s]\u001b[A\n",
      " 96%|█████████▌| 4200/4384 [23:58<00:59,  3.07it/s]\u001b[A\n",
      " 96%|█████████▌| 4201/4384 [23:58<01:01,  2.98it/s]\u001b[A\n",
      " 96%|█████████▌| 4202/4384 [23:59<00:57,  3.16it/s]\u001b[A\n",
      " 96%|█████████▌| 4203/4384 [23:59<01:00,  2.97it/s]\u001b[A\n",
      " 96%|█████████▌| 4204/4384 [23:59<00:55,  3.23it/s]\u001b[A\n",
      " 96%|█████████▌| 4205/4384 [23:59<00:51,  3.46it/s]\u001b[A\n",
      " 96%|█████████▌| 4206/4384 [24:00<00:48,  3.63it/s]\u001b[A\n",
      " 96%|█████████▌| 4207/4384 [24:00<00:47,  3.69it/s]\u001b[A\n",
      " 96%|█████████▌| 4208/4384 [24:00<00:47,  3.72it/s]\u001b[A\n",
      " 96%|█████████▌| 4209/4384 [24:01<00:50,  3.48it/s]\u001b[A\n",
      " 96%|█████████▌| 4210/4384 [24:01<00:50,  3.46it/s]\u001b[A\n",
      " 96%|█████████▌| 4211/4384 [24:01<00:49,  3.51it/s]\u001b[A\n",
      " 96%|█████████▌| 4212/4384 [24:01<00:46,  3.69it/s]\u001b[A\n",
      " 96%|█████████▌| 4213/4384 [24:02<00:44,  3.87it/s]\u001b[A\n",
      " 96%|█████████▌| 4214/4384 [24:02<00:44,  3.78it/s]\u001b[A\n",
      " 96%|█████████▌| 4215/4384 [24:02<00:44,  3.77it/s]\u001b[A\n",
      " 96%|█████████▌| 4216/4384 [24:02<00:42,  3.96it/s]\u001b[A\n",
      " 96%|█████████▌| 4217/4384 [24:03<00:43,  3.81it/s]\u001b[A\n",
      " 96%|█████████▌| 4218/4384 [24:03<00:44,  3.73it/s]\u001b[A\n",
      " 96%|█████████▌| 4219/4384 [24:03<00:41,  4.00it/s]\u001b[A\n",
      " 96%|█████████▋| 4220/4384 [24:04<00:48,  3.40it/s]\u001b[A\n",
      " 96%|█████████▋| 4221/4384 [24:04<00:48,  3.36it/s]\u001b[A\n",
      " 96%|█████████▋| 4222/4384 [24:04<00:47,  3.41it/s]\u001b[A\n",
      " 96%|█████████▋| 4223/4384 [24:04<00:42,  3.75it/s]\u001b[A\n",
      " 96%|█████████▋| 4224/4384 [24:05<00:41,  3.87it/s]\u001b[A\n",
      " 96%|█████████▋| 4225/4384 [24:05<00:40,  3.94it/s]\u001b[A\n",
      " 96%|█████████▋| 4226/4384 [24:05<00:40,  3.91it/s]\u001b[A\n",
      " 96%|█████████▋| 4227/4384 [24:05<00:41,  3.83it/s]\u001b[A\n",
      " 96%|█████████▋| 4228/4384 [24:06<00:43,  3.63it/s]\u001b[A\n",
      " 96%|█████████▋| 4229/4384 [24:06<00:45,  3.43it/s]\u001b[A\n",
      " 96%|█████████▋| 4230/4384 [24:06<00:48,  3.19it/s]\u001b[A\n",
      " 97%|█████████▋| 4231/4384 [24:07<00:48,  3.17it/s]\u001b[A\n",
      " 97%|█████████▋| 4232/4384 [24:07<00:49,  3.09it/s]\u001b[A\n",
      " 97%|█████████▋| 4233/4384 [24:07<00:47,  3.17it/s]\u001b[A\n",
      " 97%|█████████▋| 4234/4384 [24:08<00:49,  3.06it/s]\u001b[A\n",
      " 97%|█████████▋| 4235/4384 [24:08<00:44,  3.35it/s]\u001b[A\n",
      " 97%|█████████▋| 4236/4384 [24:08<00:41,  3.61it/s]\u001b[A\n",
      " 97%|█████████▋| 4237/4384 [24:08<00:39,  3.73it/s]\u001b[A\n",
      " 97%|█████████▋| 4238/4384 [24:09<00:36,  4.01it/s]\u001b[A\n",
      " 97%|█████████▋| 4239/4384 [24:09<00:37,  3.89it/s]\u001b[A\n",
      " 97%|█████████▋| 4240/4384 [24:09<00:39,  3.62it/s]\u001b[A\n",
      " 97%|█████████▋| 4241/4384 [24:09<00:37,  3.84it/s]\u001b[A\n",
      " 97%|█████████▋| 4242/4384 [24:10<00:35,  3.97it/s]\u001b[A\n",
      " 97%|█████████▋| 4243/4384 [24:10<00:37,  3.80it/s]\u001b[A\n",
      " 97%|█████████▋| 4244/4384 [24:10<00:35,  3.95it/s]\u001b[A\n",
      " 97%|█████████▋| 4245/4384 [24:10<00:36,  3.79it/s]\u001b[A\n",
      " 97%|█████████▋| 4246/4384 [24:11<00:41,  3.30it/s]\u001b[A\n",
      " 97%|█████████▋| 4247/4384 [24:11<00:40,  3.37it/s]\u001b[A\n",
      " 97%|█████████▋| 4248/4384 [24:11<00:39,  3.43it/s]\u001b[A\n",
      " 97%|█████████▋| 4249/4384 [24:12<00:38,  3.52it/s]\u001b[A\n",
      " 97%|█████████▋| 4250/4384 [24:12<00:36,  3.69it/s]\u001b[A\n",
      " 97%|█████████▋| 4251/4384 [24:12<00:36,  3.69it/s]\u001b[A\n",
      " 97%|█████████▋| 4252/4384 [24:12<00:34,  3.77it/s]\u001b[A\n",
      " 97%|█████████▋| 4253/4384 [24:13<00:37,  3.54it/s]\u001b[A\n",
      " 97%|█████████▋| 4254/4384 [24:13<00:34,  3.75it/s]\u001b[A\n",
      " 97%|█████████▋| 4255/4384 [24:13<00:34,  3.73it/s]\u001b[A\n",
      " 97%|█████████▋| 4256/4384 [24:13<00:32,  3.93it/s]\u001b[A\n",
      " 97%|█████████▋| 4257/4384 [24:14<00:35,  3.57it/s]\u001b[A\n",
      " 97%|█████████▋| 4258/4384 [24:14<00:36,  3.48it/s]\u001b[A\n",
      " 97%|█████████▋| 4259/4384 [24:14<00:36,  3.43it/s]\u001b[A\n",
      " 97%|█████████▋| 4260/4384 [24:15<00:35,  3.51it/s]\u001b[A\n",
      " 97%|█████████▋| 4261/4384 [24:15<00:33,  3.70it/s]\u001b[A\n",
      " 97%|█████████▋| 4262/4384 [24:15<00:31,  3.85it/s]\u001b[A\n",
      " 97%|█████████▋| 4263/4384 [24:15<00:30,  3.94it/s]\u001b[A\n",
      " 97%|█████████▋| 4264/4384 [24:16<00:33,  3.53it/s]\u001b[A\n",
      " 97%|█████████▋| 4265/4384 [24:16<00:35,  3.34it/s]\u001b[A\n",
      " 97%|█████████▋| 4266/4384 [24:16<00:34,  3.43it/s]\u001b[A\n",
      " 97%|█████████▋| 4267/4384 [24:17<00:33,  3.50it/s]\u001b[A\n",
      " 97%|█████████▋| 4268/4384 [24:17<00:37,  3.11it/s]\u001b[A\n",
      " 97%|█████████▋| 4269/4384 [24:17<00:34,  3.33it/s]\u001b[A\n",
      " 97%|█████████▋| 4270/4384 [24:18<00:38,  2.98it/s]\u001b[A\n",
      " 97%|█████████▋| 4271/4384 [24:18<00:37,  3.04it/s]\u001b[A\n",
      " 97%|█████████▋| 4272/4384 [24:18<00:35,  3.17it/s]\u001b[A\n",
      " 97%|█████████▋| 4273/4384 [24:19<00:33,  3.29it/s]\u001b[A\n",
      " 97%|█████████▋| 4274/4384 [24:19<00:35,  3.14it/s]\u001b[A\n",
      " 98%|█████████▊| 4275/4384 [24:19<00:31,  3.46it/s]\u001b[A\n",
      " 98%|█████████▊| 4276/4384 [24:19<00:29,  3.69it/s]\u001b[A\n",
      " 98%|█████████▊| 4277/4384 [24:20<00:28,  3.74it/s]\u001b[A\n",
      " 98%|█████████▊| 4278/4384 [24:20<00:28,  3.75it/s]\u001b[A\n",
      " 98%|█████████▊| 4279/4384 [24:20<00:26,  3.90it/s]\u001b[A\n",
      " 98%|█████████▊| 4280/4384 [24:20<00:27,  3.77it/s]\u001b[A\n",
      " 98%|█████████▊| 4281/4384 [24:21<00:27,  3.69it/s]\u001b[A\n",
      " 98%|█████████▊| 4282/4384 [24:21<00:29,  3.41it/s]\u001b[A\n",
      " 98%|█████████▊| 4283/4384 [24:21<00:28,  3.52it/s]\u001b[A\n",
      " 98%|█████████▊| 4284/4384 [24:22<00:28,  3.54it/s]\u001b[A\n",
      " 98%|█████████▊| 4285/4384 [24:22<00:28,  3.48it/s]\u001b[A\n",
      " 98%|█████████▊| 4286/4384 [24:22<00:27,  3.54it/s]\u001b[A\n",
      " 98%|█████████▊| 4287/4384 [24:22<00:26,  3.67it/s]\u001b[A\n",
      " 98%|█████████▊| 4288/4384 [24:23<00:25,  3.79it/s]\u001b[A\n",
      " 98%|█████████▊| 4289/4384 [24:23<00:23,  3.97it/s]\u001b[A\n",
      " 98%|█████████▊| 4290/4384 [24:23<00:26,  3.59it/s]\u001b[A\n",
      " 98%|█████████▊| 4291/4384 [24:23<00:25,  3.61it/s]\u001b[A\n",
      " 98%|█████████▊| 4292/4384 [24:24<00:24,  3.74it/s]\u001b[A\n",
      " 98%|█████████▊| 4293/4384 [24:24<00:23,  3.85it/s]\u001b[A\n",
      " 98%|█████████▊| 4294/4384 [24:24<00:23,  3.85it/s]\u001b[A\n",
      " 98%|█████████▊| 4295/4384 [24:25<00:23,  3.73it/s]\u001b[A\n",
      " 98%|█████████▊| 4296/4384 [24:25<00:23,  3.68it/s]\u001b[A\n",
      " 98%|█████████▊| 4297/4384 [24:25<00:23,  3.63it/s]\u001b[A\n",
      " 98%|█████████▊| 4298/4384 [24:25<00:22,  3.78it/s]\u001b[A\n",
      " 98%|█████████▊| 4299/4384 [24:26<00:24,  3.43it/s]\u001b[A\n",
      " 98%|█████████▊| 4300/4384 [24:26<00:26,  3.16it/s]\u001b[A\n",
      " 98%|█████████▊| 4301/4384 [24:26<00:25,  3.22it/s]\u001b[A\n",
      " 98%|█████████▊| 4302/4384 [24:27<00:24,  3.28it/s]\u001b[A\n",
      " 98%|█████████▊| 4303/4384 [24:27<00:23,  3.39it/s]\u001b[A\n",
      " 98%|█████████▊| 4304/4384 [24:27<00:22,  3.50it/s]\u001b[A\n",
      " 98%|█████████▊| 4305/4384 [24:27<00:22,  3.50it/s]\u001b[A\n",
      " 98%|█████████▊| 4306/4384 [24:28<00:22,  3.39it/s]\u001b[A\n",
      " 98%|█████████▊| 4307/4384 [24:28<00:21,  3.58it/s]\u001b[A\n",
      " 98%|█████████▊| 4308/4384 [24:28<00:23,  3.19it/s]\u001b[A\n",
      " 98%|█████████▊| 4309/4384 [24:29<00:23,  3.24it/s]\u001b[A\n",
      " 98%|█████████▊| 4310/4384 [24:29<00:21,  3.51it/s]\u001b[A\n",
      " 98%|█████████▊| 4311/4384 [24:29<00:21,  3.43it/s]\u001b[A\n",
      " 98%|█████████▊| 4312/4384 [24:30<00:21,  3.39it/s]\u001b[A\n",
      " 98%|█████████▊| 4313/4384 [24:30<00:20,  3.49it/s]\u001b[A\n",
      " 98%|█████████▊| 4314/4384 [24:30<00:18,  3.71it/s]\u001b[A\n",
      " 98%|█████████▊| 4315/4384 [24:30<00:17,  3.87it/s]\u001b[A\n",
      " 98%|█████████▊| 4316/4384 [24:31<00:21,  3.14it/s]\u001b[A\n",
      " 98%|█████████▊| 4317/4384 [24:31<00:19,  3.42it/s]\u001b[A\n",
      " 98%|█████████▊| 4318/4384 [24:31<00:18,  3.66it/s]\u001b[A\n",
      " 99%|█████████▊| 4319/4384 [24:31<00:17,  3.62it/s]\u001b[A\n",
      " 99%|█████████▊| 4320/4384 [24:32<00:17,  3.74it/s]\u001b[A\n",
      " 99%|█████████▊| 4321/4384 [24:32<00:18,  3.37it/s]\u001b[A\n",
      " 99%|█████████▊| 4322/4384 [24:32<00:18,  3.30it/s]\u001b[A\n",
      " 99%|█████████▊| 4323/4384 [24:33<00:18,  3.33it/s]\u001b[A\n",
      " 99%|█████████▊| 4324/4384 [24:33<00:16,  3.57it/s]\u001b[A\n",
      " 99%|█████████▊| 4325/4384 [24:33<00:16,  3.68it/s]\u001b[A\n",
      " 99%|█████████▊| 4326/4384 [24:33<00:15,  3.69it/s]\u001b[A\n",
      " 99%|█████████▊| 4327/4384 [24:34<00:16,  3.46it/s]\u001b[A\n",
      " 99%|█████████▊| 4328/4384 [24:34<00:15,  3.53it/s]\u001b[A\n",
      " 99%|█████████▊| 4329/4384 [24:34<00:14,  3.81it/s]\u001b[A\n",
      " 99%|█████████▉| 4330/4384 [24:35<00:14,  3.61it/s]\u001b[A\n",
      " 99%|█████████▉| 4331/4384 [24:35<00:14,  3.71it/s]\u001b[A\n",
      " 99%|█████████▉| 4332/4384 [24:35<00:14,  3.55it/s]\u001b[A\n",
      " 99%|█████████▉| 4333/4384 [24:35<00:13,  3.70it/s]\u001b[A\n",
      " 99%|█████████▉| 4334/4384 [24:36<00:13,  3.82it/s]\u001b[A\n",
      " 99%|█████████▉| 4335/4384 [24:36<00:14,  3.28it/s]\u001b[A\n",
      " 99%|█████████▉| 4336/4384 [24:36<00:14,  3.34it/s]\u001b[A\n",
      " 99%|█████████▉| 4337/4384 [24:37<00:12,  3.62it/s]\u001b[A\n",
      " 99%|█████████▉| 4338/4384 [24:37<00:12,  3.70it/s]\u001b[A\n",
      " 99%|█████████▉| 4339/4384 [24:37<00:13,  3.25it/s]\u001b[A\n",
      " 99%|█████████▉| 4340/4384 [24:38<00:15,  2.76it/s]\u001b[A\n",
      " 99%|█████████▉| 4341/4384 [24:38<00:13,  3.16it/s]\u001b[A\n",
      " 99%|█████████▉| 4342/4384 [24:38<00:12,  3.37it/s]\u001b[A\n",
      " 99%|█████████▉| 4343/4384 [24:38<00:11,  3.45it/s]\u001b[A\n",
      " 99%|█████████▉| 4344/4384 [24:39<00:11,  3.56it/s]\u001b[A\n",
      " 99%|█████████▉| 4345/4384 [24:39<00:10,  3.61it/s]\u001b[A\n",
      " 99%|█████████▉| 4346/4384 [24:39<00:10,  3.49it/s]\u001b[A\n",
      " 99%|█████████▉| 4347/4384 [24:40<00:10,  3.65it/s]\u001b[A\n",
      " 99%|█████████▉| 4348/4384 [24:40<00:10,  3.29it/s]\u001b[A\n",
      " 99%|█████████▉| 4349/4384 [24:40<00:10,  3.43it/s]\u001b[A\n",
      " 99%|█████████▉| 4350/4384 [24:40<00:09,  3.49it/s]\u001b[A\n",
      " 99%|█████████▉| 4351/4384 [24:41<00:09,  3.63it/s]\u001b[A\n",
      " 99%|█████████▉| 4352/4384 [24:41<00:10,  2.99it/s]\u001b[A\n",
      " 99%|█████████▉| 4353/4384 [24:41<00:10,  3.09it/s]\u001b[A\n",
      " 99%|█████████▉| 4354/4384 [24:42<00:09,  3.24it/s]\u001b[A\n",
      " 99%|█████████▉| 4355/4384 [24:42<00:10,  2.69it/s]\u001b[A\n",
      " 99%|█████████▉| 4356/4384 [24:43<00:09,  2.94it/s]\u001b[A\n",
      " 99%|█████████▉| 4357/4384 [24:43<00:08,  3.27it/s]\u001b[A\n",
      " 99%|█████████▉| 4358/4384 [24:43<00:07,  3.33it/s]\u001b[A\n",
      " 99%|█████████▉| 4359/4384 [24:43<00:07,  3.26it/s]\u001b[A\n",
      " 99%|█████████▉| 4360/4384 [24:44<00:07,  3.41it/s]\u001b[A\n",
      " 99%|█████████▉| 4361/4384 [24:44<00:06,  3.55it/s]\u001b[A\n",
      " 99%|█████████▉| 4362/4384 [24:44<00:05,  3.75it/s]\u001b[A\n",
      "100%|█████████▉| 4363/4384 [24:44<00:05,  3.59it/s]\u001b[A\n",
      "100%|█████████▉| 4364/4384 [24:45<00:05,  3.61it/s]\u001b[A\n",
      "100%|█████████▉| 4365/4384 [24:45<00:05,  3.51it/s]\u001b[A\n",
      "100%|█████████▉| 4366/4384 [24:45<00:05,  3.03it/s]\u001b[A\n",
      "100%|█████████▉| 4367/4384 [24:46<00:05,  3.20it/s]\u001b[A\n",
      "100%|█████████▉| 4368/4384 [24:46<00:04,  3.27it/s]\u001b[A\n",
      "100%|█████████▉| 4369/4384 [24:46<00:04,  3.39it/s]\u001b[A\n",
      "100%|█████████▉| 4370/4384 [24:47<00:04,  3.39it/s]\u001b[A\n",
      "100%|█████████▉| 4371/4384 [24:47<00:03,  3.77it/s]\u001b[A\n",
      "100%|█████████▉| 4372/4384 [24:47<00:03,  3.76it/s]\u001b[A\n",
      "100%|█████████▉| 4373/4384 [24:47<00:02,  3.96it/s]\u001b[A\n",
      "100%|█████████▉| 4374/4384 [24:47<00:02,  3.90it/s]\u001b[A\n",
      "100%|█████████▉| 4375/4384 [24:48<00:02,  3.42it/s]\u001b[A\n",
      "100%|█████████▉| 4376/4384 [24:48<00:02,  3.82it/s]\u001b[A\n",
      "100%|█████████▉| 4377/4384 [24:48<00:01,  3.98it/s]\u001b[A\n",
      "100%|█████████▉| 4378/4384 [24:49<00:01,  3.71it/s]\u001b[A\n",
      "100%|█████████▉| 4379/4384 [24:49<00:01,  3.78it/s]\u001b[A\n",
      "100%|█████████▉| 4380/4384 [24:49<00:01,  3.79it/s]\u001b[A\n",
      "100%|█████████▉| 4381/4384 [24:49<00:00,  3.77it/s]\u001b[A\n",
      "100%|█████████▉| 4382/4384 [24:50<00:00,  3.82it/s]\u001b[A\n",
      "100%|█████████▉| 4383/4384 [24:50<00:00,  4.01it/s]\u001b[A\n",
      "100%|██████████| 4384/4384 [24:50<00:00,  4.11it/s]\u001b[A\n",
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 3/71 [00:00<00:02, 23.40it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 4/71 [00:00<00:04, 15.38it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 6/71 [00:00<00:04, 15.52it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█▏        | 8/71 [00:00<00:04, 14.66it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 10/71 [00:00<00:03, 15.48it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 12/71 [00:00<00:04, 14.11it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 14/71 [00:00<00:04, 13.16it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 16/71 [00:01<00:03, 14.36it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 18/71 [00:01<00:04, 12.46it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 20/71 [00:01<00:03, 12.89it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 22/71 [00:01<00:03, 13.05it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 24/71 [00:01<00:03, 13.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 26/71 [00:01<00:03, 14.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 28/71 [00:01<00:03, 14.21it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 30/71 [00:02<00:03, 13.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 32/71 [00:02<00:02, 13.54it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 34/71 [00:02<00:02, 14.45it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 36/71 [00:02<00:02, 15.24it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 38/71 [00:02<00:02, 14.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 40/71 [00:02<00:02, 14.42it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 42/71 [00:02<00:01, 14.88it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 44/71 [00:03<00:02, 12.72it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 46/71 [00:03<00:02, 12.22it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 48/71 [00:03<00:01, 13.32it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 50/71 [00:03<00:01, 13.60it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 52/71 [00:03<00:01, 13.53it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 54/71 [00:03<00:01, 13.09it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 56/71 [00:04<00:01, 13.23it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 58/71 [00:04<00:00, 13.73it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 60/71 [00:04<00:00, 13.29it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 62/71 [00:04<00:00, 12.74it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 64/71 [00:04<00:00, 13.25it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 66/71 [00:04<00:00, 13.80it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 68/71 [00:04<00:00, 13.45it/s]\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "  0%|          | 14/4384 [19:43:08<22:37,  3.22it/s]\n",
      "\n",
      "100%|██████████| 71/71 [00:05<00:00, 14.82it/s]\u001b[A\u001b[A\n",
      "100%|██████████| 4384/4384 [24:56<00:00,  4.11it/s]\u001b[A\n",
      "\n",
      "\n",
      "  0%|          | 14/4384 [19:43:08<22:37,  3.22it/s]\n",
      "100%|██████████| 4384/4384 [24:56<00:00,  2.93it/s]{'eval_loss': 0.09709525853395462, 'eval_precision': 0.7576656775469832, 'eval_recall': 0.8080168776371308, 'eval_f1': 0.7820316488004084, 'eval_accuracy': 0.9750825341927369, 'eval_runtime': 5.7649, 'eval_samples_per_second': 97.834, 'epoch': 8.0}\n",
      "{'train_runtime': 1496.3621, 'train_samples_per_second': 2.93, 'epoch': 8.0}\n",
      "\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4384, training_loss=0.14673101858501017, metrics={'train_runtime': 1496.3621, 'train_samples_per_second': 2.93, 'epoch': 8.0, 'init_mem_cpu_alloc_delta': 2747863, 'init_mem_cpu_peaked_delta': 9669675, 'train_mem_cpu_alloc_delta': 540888, 'train_mem_cpu_peaked_delta': 17594827})"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKASz-2vIrJi"
   },
   "source": [
    "The `evaluate` method allows you to evaluate again on the evaluation dataset or on another dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "id": "UOUcBkX8IrJi",
    "outputId": "de5b9dd6-9dc0-4702-cb43-55e9829fde25"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]\u001b[A\n",
      "  4%|▍         | 3/71 [00:00<00:03, 22.55it/s]\u001b[A\n",
      "  6%|▌         | 4/71 [00:00<00:04, 15.35it/s]\u001b[A\n",
      "  8%|▊         | 6/71 [00:00<00:04, 15.54it/s]\u001b[A\n",
      " 11%|█▏        | 8/71 [00:00<00:04, 14.62it/s]\u001b[A\n",
      " 14%|█▍        | 10/71 [00:00<00:03, 15.39it/s]\u001b[A\n",
      " 17%|█▋        | 12/71 [00:00<00:04, 14.29it/s]\u001b[A\n",
      " 20%|█▉        | 14/71 [00:00<00:04, 13.37it/s]\u001b[A\n",
      " 23%|██▎       | 16/71 [00:01<00:03, 14.62it/s]\u001b[A\n",
      " 25%|██▌       | 18/71 [00:01<00:04, 12.98it/s]\u001b[A\n",
      " 28%|██▊       | 20/71 [00:01<00:03, 13.59it/s]\u001b[A\n",
      " 31%|███       | 22/71 [00:01<00:03, 13.63it/s]\u001b[A\n",
      " 34%|███▍      | 24/71 [00:01<00:03, 14.05it/s]\u001b[A\n",
      " 37%|███▋      | 26/71 [00:01<00:03, 14.76it/s]\u001b[A\n",
      " 39%|███▉      | 28/71 [00:01<00:02, 14.74it/s]\u001b[A\n",
      " 42%|████▏     | 30/71 [00:02<00:02, 14.03it/s]\u001b[A\n",
      " 45%|████▌     | 32/71 [00:02<00:02, 14.09it/s]\u001b[A\n",
      " 48%|████▊     | 34/71 [00:02<00:02, 15.32it/s]\u001b[A\n",
      " 51%|█████     | 36/71 [00:02<00:02, 16.15it/s]\u001b[A\n",
      " 54%|█████▎    | 38/71 [00:02<00:02, 15.77it/s]\u001b[A\n",
      " 56%|█████▋    | 40/71 [00:02<00:02, 15.20it/s]\u001b[A\n",
      " 59%|█████▉    | 42/71 [00:02<00:01, 15.65it/s]\u001b[A\n",
      " 62%|██████▏   | 44/71 [00:02<00:01, 15.16it/s]\u001b[A\n",
      " 65%|██████▍   | 46/71 [00:03<00:01, 14.29it/s]\u001b[A\n",
      " 68%|██████▊   | 48/71 [00:03<00:01, 15.37it/s]\u001b[A\n",
      " 70%|███████   | 50/71 [00:03<00:01, 15.55it/s]\u001b[A\n",
      " 73%|███████▎  | 52/71 [00:03<00:01, 15.25it/s]\u001b[A\n",
      " 76%|███████▌  | 54/71 [00:03<00:01, 14.33it/s]\u001b[A\n",
      " 79%|███████▉  | 56/71 [00:03<00:01, 14.42it/s]\u001b[A\n",
      " 82%|████████▏ | 58/71 [00:03<00:00, 14.86it/s]\u001b[A\n",
      " 85%|████████▍ | 60/71 [00:04<00:00, 14.08it/s]\u001b[A\n",
      " 87%|████████▋ | 62/71 [00:04<00:00, 13.48it/s]\u001b[A\n",
      " 90%|█████████ | 64/71 [00:04<00:00, 14.09it/s]\u001b[A\n",
      " 93%|█████████▎| 66/71 [00:04<00:00, 14.70it/s]\u001b[A\n",
      " 96%|█████████▌| 68/71 [00:04<00:00, 14.26it/s]\u001b[A\n",
      "100%|██████████| 71/71 [00:05<00:00, 13.23it/s]\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'eval_loss': 0.09709525853395462,\n",
       " 'eval_precision': 0.7576656775469832,\n",
       " 'eval_recall': 0.8080168776371308,\n",
       " 'eval_f1': 0.7820316488004084,\n",
       " 'eval_accuracy': 0.9750825341927369,\n",
       " 'eval_runtime': 5.4442,\n",
       " 'eval_samples_per_second': 103.596,\n",
       " 'epoch': 8.0,\n",
       " 'eval_mem_cpu_alloc_delta': 2371531,\n",
       " 'eval_mem_cpu_peaked_delta': 1994333}"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the precision/recall/f1 computed for each category now that we have finished training, we can apply the same function as before on the result of the `predict` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "  0%|          | 14/4384 [20:00:19<6244:33:48, 5144.26s/it]\n",
      "\n",
      "72it [17:05, 306.44s/it]                       \u001b[A\n",
      "74it [17:06, 214.53s/it]\u001b[A\n",
      "76it [17:06, 150.19s/it]\u001b[A\n",
      "78it [17:06, 105.15s/it]\u001b[A\n",
      "81it [17:06, 73.62s/it] \u001b[A\n",
      "83it [17:06, 51.56s/it]\u001b[A\n",
      "85it [17:06, 36.11s/it]\u001b[A\n",
      "87it [17:06, 25.29s/it]\u001b[A\n",
      "89it [17:06, 17.73s/it]\u001b[A\n",
      "91it [17:07, 12.43s/it]\u001b[A\n",
      "93it [17:07,  8.72s/it]\u001b[A\n",
      "95it [17:07,  6.14s/it]\u001b[A\n",
      "97it [17:07,  4.32s/it]\u001b[A\n",
      "99it [17:07,  3.05s/it]\u001b[A\n",
      "101it [17:07,  2.15s/it]\u001b[A\n",
      "103it [17:08,  1.53s/it]\u001b[A\n",
      "105it [17:08,  1.09s/it]\u001b[A\n",
      "107it [17:08,  1.27it/s]\u001b[A\n",
      "109it [17:08,  1.76it/s]\u001b[A\n",
      "111it [17:08,  2.38it/s]\u001b[A\n",
      "113it [17:08,  3.16it/s]\u001b[A\n",
      "115it [17:08,  4.17it/s]\u001b[A\n",
      "117it [17:09,  5.38it/s]\u001b[A\n",
      "119it [17:09,  6.74it/s]\u001b[A\n",
      "121it [17:09,  8.09it/s]\u001b[A\n",
      "123it [17:09,  9.19it/s]\u001b[A\n",
      "125it [17:09, 10.11it/s]\u001b[A\n",
      "127it [17:09, 11.03it/s]\u001b[A\n",
      "129it [17:09, 11.72it/s]\u001b[A\n",
      "131it [17:10, 11.65it/s]\u001b[A\n",
      "133it [17:10, 10.51it/s]\u001b[A\n",
      "135it [17:10, 11.90it/s]\u001b[A\n",
      "137it [17:10, 12.42it/s]\u001b[A\n",
      "139it [17:10, 13.03it/s]\u001b[A\n",
      "141it [17:10, 13.39it/s]\u001b[A"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'LOC': {'precision': 0.6651982378854625,\n",
       "  'recall': 0.8206521739130435,\n",
       "  'f1': 0.7347931873479319,\n",
       "  'number': 184},\n",
       " 'MISC': {'precision': 0.6061643835616438,\n",
       "  'recall': 0.6082474226804123,\n",
       "  'f1': 0.6072041166380788,\n",
       "  'number': 291},\n",
       " 'ORG': {'precision': 0.7284345047923323,\n",
       "  'recall': 0.6440677966101694,\n",
       "  'f1': 0.6836581709145427,\n",
       "  'number': 354},\n",
       " 'PER': {'precision': 0.8486842105263158,\n",
       "  'recall': 0.862876254180602,\n",
       "  'f1': 0.855721393034826,\n",
       "  'number': 299},\n",
       " 'overall_precision': 0.7165492957746479,\n",
       " 'overall_recall': 0.7216312056737588,\n",
       " 'overall_f1': 0.7190812720848055,\n",
       " 'overall_accuracy': 0.9649279118742913}"
      ]
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "predictions, labels, _ = trainer.predict(tokenized_datasets[\"test\"])\n",
    "predictions = np.argmax(predictions, axis=2)\n",
    "\n",
    "# Remove ignored index (special tokens)\n",
    "true_predictions = [\n",
    "    [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "true_labels = [\n",
    "    [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
    "    for prediction, label in zip(predictions, labels)\n",
    "]\n",
    "\n",
    "results = metric.compute(predictions=true_predictions, references=true_labels)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'input_ids': [2,\n",
       "  4717,\n",
       "  5978,\n",
       "  13627,\n",
       "  3644,\n",
       "  9366,\n",
       "  3622,\n",
       "  3426,\n",
       "  1979,\n",
       "  17172,\n",
       "  2961,\n",
       "  17023,\n",
       "  1926,\n",
       "  21392,\n",
       "  1916,\n",
       "  23255,\n",
       "  1028,\n",
       "  27938,\n",
       "  2570,\n",
       "  1959,\n",
       "  16,\n",
       "  1934,\n",
       "  8901,\n",
       "  1996,\n",
       "  24049,\n",
       "  2335,\n",
       "  1944,\n",
       "  6,\n",
       "  6221,\n",
       "  1014,\n",
       "  6107,\n",
       "  6,\n",
       "  18,\n",
       "  3],\n",
       " 'labels': [-100,\n",
       "  0,\n",
       "  0,\n",
       "  7,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  2,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  5,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  -100],\n",
       " 'token_type_ids': [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0]}"
      ]
     },
     "metadata": {},
     "execution_count": 61
    }
   ],
   "source": [
    "tokenized_datasets[\"test\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to [update your model](https://huggingface.co/transformers/model_sharing.html) on the [🤗 Model Hub](https://huggingface.co/models). You can then use it only to generate results like the one shown in the first picture of this notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'keys'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-62-692cc0acfdc3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Hej mit navn er Malte\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, test_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1731\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1732\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1733\u001b[1;33m         output = self.prediction_loop(\n\u001b[0m\u001b[0;32m   1734\u001b[0m             \u001b[0mtest_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdescription\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"Prediction\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric_key_prefix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1735\u001b[0m         )\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\trainer.py\u001b[0m in \u001b[0;36mprediction_loop\u001b[1;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[0;32m   1802\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval_dataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1803\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1804\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1805\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1806\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mloss\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    515\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 517\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    519\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 557\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# may raise StopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\cds\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python38\\site-packages\\transformers\\data\\data_collator.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, features)\u001b[0m\n\u001b[0;32m    168\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    169\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 170\u001b[1;33m         \u001b[0mlabel_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"label\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[1;34m\"label\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"labels\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    171\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mlabel_name\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mlabel_name\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m         batch = self.tokenizer.pad(\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "trainer.predict(\"Hej mit navn er Malte\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\".ajjaja\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "path = Path.cwd() / \"models\"\n",
    "trainer.save_model(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "n9qywopnIrJH",
    "545PP3o8IrJV",
    "7k8ge1L1IrJk"
   ],
   "name": "Token classification",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "051aa783ff9e47e28d1f9584043815f5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "0984b2a14115454bbb009df71c1cf36f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cbea68b25d6d4ba09b2ce0f27b1726d5",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9de740e007141958545e269372780a4",
      "value": 1
     }
    },
    "0b7c8f1939074794b3d9221244b1344d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "160bf88485f44f5cb6eaeecba5e0901f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1a65887eb37747ddb75dc4a40f7285f2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_aa781f0cfe454e9da5b53b93e9baabd8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_50d325cdb9844f62a9ecc98e768cb5af",
      "value": 1
     }
    },
    "1aca01c1d8c940dfadd3e7144bb35718": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_940d00556cb849b3a689d56e274041c2",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fea27ca6c9504fc896181bc1ff5730e5",
      "value": 1
     }
    },
    "2361ab124daf47cc885ff61f2899b2af": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "299f4b4c07654e53a25f8192bd1d7bbd": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "2ace4dc78e2f4f1492a181bcd63304e7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2b34de08115d49d285def9269a53f484": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2f5223f26c8541fc87e91d2205c39995": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31b1c8a2e3334b72b45b083688c1a20c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2f5223f26c8541fc87e91d2205c39995",
      "placeholder": "​",
      "style": "IPY_MODEL_a71908883b064e1fbdddb547a8c41743",
      "value": " 4.39k/? [00:00&lt;00:00, 149kB/s]"
     }
    },
    "3c946e2260704e6c98593136bd32d921": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7e29a8b952cf4f4ea42833c8bf55342f",
      "placeholder": "​",
      "style": "IPY_MODEL_6bb68d3887ef43809eb23feb467f9723",
      "value": " 1063/0 [00:00&lt;00:00, 12337.52 examples/s]"
     }
    },
    "3f74532faa86412293d90d3952f38c4a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "46c2b043c0f84806978784a45a4e203b": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "50615aa59c7247c4804ca5cbc7945bd7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ad04ed1038154081bbb0c1444784dcc2",
      "max": 7826,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_299f4b4c07654e53a25f8192bd1d7bbd",
      "value": 7826
     }
    },
    "50d325cdb9844f62a9ecc98e768cb5af": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "5781fc45cf8d486cb06ed68853b2c644": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5cdf9ed939fb42d4bf77301c80b8afca": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5fa26fc336274073abbd1d550542ee33": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "69caab03d6264fef9fc5649bffff5e20": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_50615aa59c7247c4804ca5cbc7945bd7",
       "IPY_MODEL_fe962391292a413ca55dc932c4279fa7"
      ],
      "layout": "IPY_MODEL_3f74532faa86412293d90d3952f38c4a"
     }
    },
    "6bb68d3887ef43809eb23feb467f9723": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6c1db72efff5476e842c1386fadbbdba": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2b34de08115d49d285def9269a53f484",
      "placeholder": "​",
      "style": "IPY_MODEL_5fa26fc336274073abbd1d550542ee33",
      "value": " 28.7k/? [00:00&lt;00:00, 571kB/s]"
     }
    },
    "745c0d47d672477b9bb0dae77b926364": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a7204ade36314c86907c562e0a2158b8",
      "max": 376971,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d298eb19eeff453cba51c2804629d3f4",
      "value": 376971
     }
    },
    "75103f83538d44abada79b51a1cec09e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7c667ad22b5740d5a6319f1b1e3a8097": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7e29a8b952cf4f4ea42833c8bf55342f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7fb7c36adc624f7dbbcb4a831c1e4f63": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "80e2943be35f46eeb24c8ab13faa6578": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_931db1f7a42f4b46b7ff8c2e1262b994",
       "IPY_MODEL_6c1db72efff5476e842c1386fadbbdba"
      ],
      "layout": "IPY_MODEL_de5956b5008d4fdba807bae57509c393"
     }
    },
    "8ab9dfce29854049912178941ef1b289": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2a92143a08a4951b55bab9bc0a6d0d3",
      "placeholder": "​",
      "style": "IPY_MODEL_5781fc45cf8d486cb06ed68853b2c644",
      "value": " 8551/0 [00:00&lt;00:00, 25108.88 examples/s]"
     }
    },
    "931db1f7a42f4b46b7ff8c2e1262b994": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d30a66df5c0145e79693e09789d96b81",
      "max": 4473,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_ccd2f37647c547abb4c719b75a26f2de",
      "value": 4473
     }
    },
    "940d00556cb849b3a689d56e274041c2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "94b39ccfef0b4b08bf2fb61bb0a657c1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9a55087c85b74ea08b3e952ac1d73cbe": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a65887eb37747ddb75dc4a40f7285f2",
       "IPY_MODEL_3c946e2260704e6c98593136bd32d921"
      ],
      "layout": "IPY_MODEL_2361ab124daf47cc885ff61f2899b2af"
     }
    },
    "9fbbaae50e6743f2aa19342152398186": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_94b39ccfef0b4b08bf2fb61bb0a657c1",
      "placeholder": "​",
      "style": "IPY_MODEL_5cdf9ed939fb42d4bf77301c80b8afca",
      "value": " 1043/0 [00:00&lt;00:00, 13590.50 examples/s]"
     }
    },
    "a14c3e40e5254d61ba146f6ec88eae25": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1aca01c1d8c940dfadd3e7144bb35718",
       "IPY_MODEL_9fbbaae50e6743f2aa19342152398186"
      ],
      "layout": "IPY_MODEL_c4ffe6f624ce4e978a0d9b864544941a"
     }
    },
    "a71908883b064e1fbdddb547a8c41743": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a7204ade36314c86907c562e0a2158b8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "aa781f0cfe454e9da5b53b93e9baabd8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ad04ed1038154081bbb0c1444784dcc2": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bbee008c2791443d8610371d1f16b62b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: ",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0b7c8f1939074794b3d9221244b1344d",
      "max": 1586,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7fb7c36adc624f7dbbcb4a831c1e4f63",
      "value": 1586
     }
    },
    "c4ffe6f624ce4e978a0d9b864544941a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9de740e007141958545e269372780a4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "cbea68b25d6d4ba09b2ce0f27b1726d5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ccd2f37647c547abb4c719b75a26f2de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d22ab78269cd4ccfbcf70c707057c31b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_75103f83538d44abada79b51a1cec09e",
      "placeholder": "​",
      "style": "IPY_MODEL_e35d42b2d352498ca3fc8530393786b2",
      "value": " 377k/377k [00:00&lt;00:00, 703kB/s]"
     }
    },
    "d298eb19eeff453cba51c2804629d3f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d2a92143a08a4951b55bab9bc0a6d0d3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d30a66df5c0145e79693e09789d96b81": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d426be871b424affb455aeb7db5e822e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_745c0d47d672477b9bb0dae77b926364",
       "IPY_MODEL_d22ab78269cd4ccfbcf70c707057c31b"
      ],
      "layout": "IPY_MODEL_160bf88485f44f5cb6eaeecba5e0901f"
     }
    },
    "dd5997d01d8947e4b1c211433969b89b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bbee008c2791443d8610371d1f16b62b",
       "IPY_MODEL_31b1c8a2e3334b72b45b083688c1a20c"
      ],
      "layout": "IPY_MODEL_2ace4dc78e2f4f1492a181bcd63304e7"
     }
    },
    "de5956b5008d4fdba807bae57509c393": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e35d42b2d352498ca3fc8530393786b2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f6253931d90543e9b5fd0bb2d615f73a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_0984b2a14115454bbb009df71c1cf36f",
       "IPY_MODEL_8ab9dfce29854049912178941ef1b289"
      ],
      "layout": "IPY_MODEL_051aa783ff9e47e28d1f9584043815f5"
     }
    },
    "fe962391292a413ca55dc932c4279fa7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_46c2b043c0f84806978784a45a4e203b",
      "placeholder": "​",
      "style": "IPY_MODEL_7c667ad22b5740d5a6319f1b1e3a8097",
      "value": " 28.7k/? [00:00&lt;00:00, 652kB/s]"
     }
    },
    "fea27ca6c9504fc896181bc1ff5730e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}